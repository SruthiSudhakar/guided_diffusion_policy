digraph {
	graph [size="472.34999999999997,472.34999999999997"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140044873135664 [label="
 ()" fillcolor=darkolivegreen1]
	140043443897200 [label="MeanBackward0
---------------------
self_numel:      2048
self_sizes: (1, 2048)"]
	140043443896528 -> 140043443897200
	140043443896528 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 2048)"]
	140052605484480 -> 140043443896528
	140052605484480 [label="PermuteBackward0
----------------
dims: (0, 1)"]
	140044873377104 -> 140052605484480
	140044873377104 [label="UnsafeViewBackward0
------------------------
self_sizes: (1, 16, 128)"]
	140044873379600 -> 140044873377104
	140044873379600 [label=CloneBackward0]
	140044873379696 -> 140044873379600
	140044873379696 -> 140044873135584 [dir=none]
	140044873135584 [label="other
 (1, 16, 128)" fillcolor=orange]
	140044873379696 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140044873379456 -> 140044873379696
	140044873379456 -> 140044873119360 [dir=none]
	140044873119360 [label="self
 (1, 16, 128)" fillcolor=orange]
	140044873379456 -> 140044873115984 [dir=none]
	140044873115984 [label="target
 (1, 16, 128)" fillcolor=orange]
	140044873379456 [label="MseLossBackward0
-------------------------
reduction:              0
self     : [saved tensor]
target   : [saved tensor]"]
	140044873379312 -> 140044873379456
	140044873379312 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 16, 128)"]
	140044873379360 -> 140044873379312
	140044873379360 [label="PermuteBackward0
----------------
dims: (0, 2, 1)"]
	140044873379024 -> 140044873379360
	140044873379024 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 128, 16)"]
	140044873379072 -> 140044873379024
	140044873379072 -> 140044873135504 [dir=none]
	140044873135504 [label="input
 (1, 512, 16)" fillcolor=orange]
	140044873379072 -> 140052779231888 [dir=none]
	140052779231888 [label="weight
 (128, 512, 1)" fillcolor=orange]
	140044873379072 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (128,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (0,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044873376864 -> 140044873379072
	140044873376864 -> 140044873135424 [dir=none]
	140044873135424 [label="self
 (1, 512, 16)" fillcolor=orange]
	140044873376864 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044873376144 -> 140044873376864
	140044873376144 -> 140044873135344 [dir=none]
	140044873135344 [label="input
 (1, 512, 16)" fillcolor=orange]
	140044873376144 -> 140044873116064 [dir=none]
	140044873116064 [label="result1
 (1, 8)" fillcolor=orange]
	140044873376144 -> 140044873851904 [dir=none]
	140044873851904 [label="result2
 (1, 8)" fillcolor=orange]
	140044873376144 -> 140052779231728 [dir=none]
	140052779231728 [label="weight
 (512)" fillcolor=orange]
	140044873376144 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :             16
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044873378208 -> 140044873376144
	140044873378208 -> 140044873133168 [dir=none]
	140044873133168 [label="input
 (1, 512, 16)" fillcolor=orange]
	140044873378208 -> 140052779231568 [dir=none]
	140052779231568 [label="weight
 (512, 512, 5)" fillcolor=orange]
	140044873378208 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (512,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044873379792 -> 140044873378208
	140044873379792 -> 140044873135024 [dir=none]
	140044873135024 [label="input
 (1, 512, 8)" fillcolor=orange]
	140044873379792 -> 140052779231408 [dir=none]
	140052779231408 [label="weight
 (512, 512, 4)" fillcolor=orange]
	140044873379792 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (512,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (1,)
stride        :           (2,)
transposed    :           True
weight        : [saved tensor]"]
	140044872646864 -> 140044873379792
	140044872646864 [label="AddBackward0
------------
alpha: 1"]
	140044872647056 -> 140044872646864
	140044872647056 -> 140044873135264 [dir=none]
	140044873135264 [label="self
 (1, 512, 8)" fillcolor=orange]
	140044872647056 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872647200 -> 140044872647056
	140044872647200 -> 140044873135184 [dir=none]
	140044873135184 [label="input
 (1, 512, 8)" fillcolor=orange]
	140044872647200 -> 140044873111888 [dir=none]
	140044873111888 [label="result1
 (1, 8)" fillcolor=orange]
	140044872647200 -> 140044873111248 [dir=none]
	140044873111248 [label="result2
 (1, 8)" fillcolor=orange]
	140044872647200 -> 140052779231088 [dir=none]
	140052779231088 [label="weight
 (512)" fillcolor=orange]
	140044872647200 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              8
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872647296 -> 140044872647200
	140044872647296 -> 140044873135104 [dir=none]
	140044873135104 [label="input
 (1, 512, 8)" fillcolor=orange]
	140044872647296 -> 140052779230928 [dir=none]
	140052779230928 [label="weight
 (512, 512, 5)" fillcolor=orange]
	140044872647296 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (512,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872647488 -> 140044872647296
	140044872647488 [label="AddBackward0
------------
alpha: 1"]
	140044872647680 -> 140044872647488
	140044872647680 -> 140044873134224 [dir=none]
	140044873134224 [label="other
 (1, 512, 8)" fillcolor=orange]
	140044872647680 -> 140044873134864 [dir=none]
	140044873134864 [label="self
 (1, 512, 1)" fillcolor=orange]
	140044872647680 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140044872647824 -> 140044872647680
	140044872647824 [label="SelectBackward0
--------------------------
dim       :              1
index     :              0
self_sizes: (1, 2, 512, 1)"]
	140044872647968 -> 140044872647824
	140044872647968 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:      (1, 2, 512, 1)
start     :                   0
step      :                   1"]
	140044872648112 -> 140044872647968
	140044872648112 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 1024, 1)"]
	140044872648208 -> 140044872648112
	140044872648208 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 1024)"]
	140044872648304 -> 140044872648208
	140044872648304 [label="PermuteBackward0
----------------
dims: (0, 1)"]
	140044872648400 -> 140044872648304
	140044872648400 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 1024)"]
	140044872648496 -> 140044872648400
	140044872648496 -> 140044873134704 [dir=none]
	140044873134704 [label="mat1
 (1, 402)" fillcolor=orange]
	140044872648496 -> 140044873136784 [dir=none]
	140044873136784 [label="mat2
 (402, 1024)" fillcolor=orange]
	140044872648496 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 402)
mat1_strides:       (402, 1)
mat2        : [saved tensor]
mat2_sizes  :    (402, 1024)
mat2_strides:       (1, 402)"]
	140044872648592 -> 140044872648496
	140052779231328 [label="model.up_modules.1.1.cond_encoder.1.bias
 (1024)" fillcolor=lightblue]
	140052779231328 -> 140044872648592
	140044872648592 [label=AccumulateGrad]
	140044872648544 -> 140044872648496
	140044872648544 -> 140044873119600 [dir=none]
	140044873119600 [label="self
 (1, 402)" fillcolor=orange]
	140044872648544 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872648688 -> 140044872648544
	140044872648688 [label="CatBackward0
-------------------------
dim: 18446744073709551615"]
	140044872648928 -> 140044872648688
	140044872648928 -> 140044873119520 [dir=none]
	140044873119520 [label="mat1
 (1, 512)" fillcolor=orange]
	140044872648928 -> 140053581096016 [dir=none]
	140053581096016 [label="mat2
 (512, 128)" fillcolor=orange]
	140044872648928 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 512)
mat1_strides:       (512, 1)
mat2        : [saved tensor]
mat2_sizes  :     (512, 128)
mat2_strides:       (1, 512)"]
	140044872649072 -> 140044872648928
	140052785259200 [label="model.diffusion_step_encoder.3.bias
 (128)" fillcolor=lightblue]
	140052785259200 -> 140044872649072
	140044872649072 [label=AccumulateGrad]
	140044872648976 -> 140044872648928
	140044872648976 -> 140044873119840 [dir=none]
	140044873119840 [label="self
 (1, 512)" fillcolor=orange]
	140044872648976 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872649168 -> 140044872648976
	140044872649168 -> 140044873119760 [dir=none]
	140044873119760 [label="mat1
 (1, 128)" fillcolor=orange]
	140044872649168 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 128)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :     (128, 512)
mat2_strides:       (1, 128)"]
	140044872649360 -> 140044872649168
	140052785259680 [label="model.diffusion_step_encoder.1.bias
 (512)" fillcolor=lightblue]
	140052785259680 -> 140044872649360
	140044872649360 [label=AccumulateGrad]
	140044872649312 -> 140044872649168
	140044872649312 [label=TBackward0]
	140044872649408 -> 140044872649312
	140052785260720 [label="model.diffusion_step_encoder.1.weight
 (512, 128)" fillcolor=lightblue]
	140052785260720 -> 140044872649408
	140044872649408 [label=AccumulateGrad]
	140044872649024 -> 140044872648928
	140044872649024 [label=TBackward0]
	140044872649456 -> 140044872649024
	140052785261840 [label="model.diffusion_step_encoder.3.weight
 (128, 512)" fillcolor=lightblue]
	140052785261840 -> 140044872649456
	140044872649456 [label=AccumulateGrad]
	140044872648880 -> 140044872648688
	140044872648880 [label="ReshapeAliasBackward0
---------------------
self_sizes: (2, 137)"]
	140044872649552 -> 140044872648880
	140044872649552 [label="CatBackward0
-------------------------
dim: 18446744073709551615"]
	140044872649504 -> 140044872649552
	140044872649504 [label="ReshapeAliasBackward0
---------------------
self_sizes: (2, 64)"]
	140044872649744 -> 140044872649504
	140044872649744 -> 140044873135824 [dir=none]
	140044873135824 [label="result
 (2, 64)" fillcolor=orange]
	140044872649744 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872649840 -> 140044872649744
	140044872649840 -> 140044873112848 [dir=none]
	140044873112848 [label="mat1
 (2, 64)" fillcolor=orange]
	140044872649840 -> 140044873136944 [dir=none]
	140044873136944 [label="mat2
 (64, 64)" fillcolor=orange]
	140044872649840 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :        (2, 64)
mat1_strides:        (64, 1)
mat2        : [saved tensor]
mat2_sizes  :       (64, 64)
mat2_strides:        (1, 64)"]
	140044872649936 -> 140044872649840
	140052784926128 [label="obs_encoder.obs_nets.agentview_image.nets.3.bias
 (64)" fillcolor=lightblue]
	140052784926128 -> 140044872649936
	140044872649936 [label=AccumulateGrad]
	140044872649888 -> 140044872649840
	140044872649888 [label="ReshapeAliasBackward0
----------------------
self_sizes: (2, 32, 2)"]
	140044872650032 -> 140044872649888
	140044872650032 [label="AsStridedBackward0
--------------------------
size          : (2, 32, 2)
storage_offset:          0
stride        : (64, 2, 1)"]
	140044872650224 -> 140044872650032
	140044872650224 [label=CopySlices]
	140044872650320 -> 140044872650224
	140044872650320 [label="CatBackward0
------------
dim: 1"]
	140044872650416 -> 140044872650320
	140044872650416 [label="SumBackward1
-------------------
dim       :    (1,)
keepdim   :    True
self_sizes: (64, 9)"]
	140044872650560 -> 140044872650416
	140044872650560 -> 140052784925888 [dir=none]
	140052784925888 [label="self
 (1, 9)" fillcolor=orange]
	140044872650560 [label="MulBackward0
---------------------
other:           None
self : [saved tensor]"]
	140044872650656 -> 140044872650560
	140044872650656 -> 140044873136544 [dir=none]
	140044873136544 [label="result
 (64, 9)" fillcolor=orange]
	140044872650656 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140044872650704 -> 140044872650656
	140044872650704 -> 140043446845088 [dir=none]
	140043446845088 [label="other
 (1)" fillcolor=orange]
	140044872650704 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	140044872679584 -> 140044872650704
	140044872679584 [label="ReshapeAliasBackward0
-------------------------
self_sizes: (2, 32, 3, 3)"]
	140044872679680 -> 140044872679584
	140044872679680 -> 140044873115424 [dir=none]
	140044873115424 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872679680 -> 140052784925808 [dir=none]
	140052784925808 [label="weight
 (32, 512, 1, 1)" fillcolor=orange]
	140044872679680 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:          (32,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872679872 -> 140044872679680
	140044872679872 -> 140044873136464 [dir=none]
	140044873136464 [label="result
 (2, 512, 3, 3)" fillcolor=orange]
	140044872679872 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872680064 -> 140044872679872
	140044872680064 [label="AddBackward0
------------
alpha: 1"]
	140044872680160 -> 140044872680064
	140044872680160 -> 140044873115344 [dir=none]
	140044873115344 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872680160 -> 140044873136704 [dir=none]
	140044873136704 [label="result1
 (2, 32)" fillcolor=orange]
	140044872680160 -> 140044873137104 [dir=none]
	140044873137104 [label="result2
 (2, 32)" fillcolor=orange]
	140044872680160 -> 140052784925008 [dir=none]
	140052784925008 [label="weight
 (512)" fillcolor=orange]
	140044872680160 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              9
N      :              2
eps    :          1e-05
group  :             32
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872680352 -> 140044872680160
	140044872680352 -> 140044873115104 [dir=none]
	140044873115104 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872680352 -> 140052784925408 [dir=none]
	140052784925408 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	140044872680352 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872680544 -> 140044872680352
	140044872680544 -> 140044873135744 [dir=none]
	140044873135744 [label="result
 (2, 512, 3, 3)" fillcolor=orange]
	140044872680544 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872680688 -> 140044872680544
	140044872680688 -> 140044873115264 [dir=none]
	140044873115264 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872680688 -> 140044873137344 [dir=none]
	140044873137344 [label="result1
 (2, 32)" fillcolor=orange]
	140044872680688 -> 140044873137184 [dir=none]
	140044873137184 [label="result2
 (2, 32)" fillcolor=orange]
	140044872680688 -> 140052784923328 [dir=none]
	140052784923328 [label="weight
 (512)" fillcolor=orange]
	140044872680688 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              9
N      :              2
eps    :          1e-05
group  :             32
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872680832 -> 140044872680688
	140044872680832 -> 140044873115024 [dir=none]
	140044873115024 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872680832 -> 140052784924848 [dir=none]
	140052784924848 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	140044872680832 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872680112 -> 140044872680832
	140044872680112 -> 140044873137264 [dir=none]
	140044873137264 [label="result
 (2, 512, 3, 3)" fillcolor=orange]
	140044872680112 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872681120 -> 140044872680112
	140044872681120 [label="AddBackward0
------------
alpha: 1"]
	140044872681216 -> 140044872681120
	140044872681216 -> 140044873114944 [dir=none]
	140044873114944 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872681216 -> 140044873137664 [dir=none]
	140044873137664 [label="result1
 (2, 32)" fillcolor=orange]
	140044872681216 -> 140044873136384 [dir=none]
	140044873136384 [label="result2
 (2, 32)" fillcolor=orange]
	140044872681216 -> 140052784923968 [dir=none]
	140052784923968 [label="weight
 (512)" fillcolor=orange]
	140044872681216 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              9
N      :              2
eps    :          1e-05
group  :             32
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872681408 -> 140044872681216
	140044872681408 -> 140044873114864 [dir=none]
	140044873114864 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872681408 -> 140052784924368 [dir=none]
	140052784924368 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	140044872681408 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872681600 -> 140044872681408
	140044872681600 -> 140044873137584 [dir=none]
	140044873137584 [label="result
 (2, 512, 3, 3)" fillcolor=orange]
	140044872681600 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872681744 -> 140044872681600
	140044872681744 -> 140044873114784 [dir=none]
	140044873114784 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872681744 -> 140044873137904 [dir=none]
	140044873137904 [label="result1
 (2, 32)" fillcolor=orange]
	140044872681744 -> 140044873136624 [dir=none]
	140044873136624 [label="result2
 (2, 32)" fillcolor=orange]
	140044872681744 -> 140052784848464 [dir=none]
	140052784848464 [label="weight
 (512)" fillcolor=orange]
	140044872681744 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              9
N      :              2
eps    :          1e-05
group  :             32
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872681888 -> 140044872681744
	140044872681888 -> 140044873114704 [dir=none]
	140044873114704 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872681888 -> 140052784923808 [dir=none]
	140052784923808 [label="weight
 (512, 256, 3, 3)" fillcolor=orange]
	140044872681888 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872682080 -> 140044872681888
	140044872682080 -> 140044873137824 [dir=none]
	140044873137824 [label="result
 (2, 256, 5, 5)" fillcolor=orange]
	140044872682080 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872682224 -> 140044872682080
	140044872682224 [label="AddBackward0
------------
alpha: 1"]
	140044872682320 -> 140044872682224
	140044872682320 -> 140044873114624 [dir=none]
	140044873114624 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872682320 -> 140044873137024 [dir=none]
	140044873137024 [label="result1
 (2, 16)" fillcolor=orange]
	140044872682320 -> 140044873136864 [dir=none]
	140044873136864 [label="result2
 (2, 16)" fillcolor=orange]
	140044872682320 -> 140052784848384 [dir=none]
	140052784848384 [label="weight
 (256)" fillcolor=orange]
	140044872682320 [label="NativeGroupNormBackward0
------------------------
C      :            256
HxW    :             25
N      :              2
eps    :          1e-05
group  :             16
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872682512 -> 140044872682320
	140044872682512 -> 140044873114384 [dir=none]
	140044873114384 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872682512 -> 140052784848784 [dir=none]
	140052784848784 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	140044872682512 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872682704 -> 140044872682512
	140044872682704 -> 140044873138064 [dir=none]
	140044873138064 [label="result
 (2, 256, 5, 5)" fillcolor=orange]
	140044872682704 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872682848 -> 140044872682704
	140044872682848 -> 140044873114544 [dir=none]
	140044873114544 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872682848 -> 140044873137984 [dir=none]
	140044873137984 [label="result1
 (2, 16)" fillcolor=orange]
	140044872682848 -> 140044873137424 [dir=none]
	140044873137424 [label="result2
 (2, 16)" fillcolor=orange]
	140044872682848 -> 140052784846704 [dir=none]
	140052784846704 [label="weight
 (256)" fillcolor=orange]
	140044872682848 [label="NativeGroupNormBackward0
------------------------
C      :            256
HxW    :             25
N      :              2
eps    :          1e-05
group  :             16
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872682992 -> 140044872682848
	140044872682992 -> 140044873114304 [dir=none]
	140044873114304 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872682992 -> 140052784848224 [dir=none]
	140052784848224 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	140044872682992 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872682272 -> 140044872682992
	140044872682272 -> 140044873137504 [dir=none]
	140044873137504 [label="result
 (2, 256, 5, 5)" fillcolor=orange]
	140044872682272 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872683280 -> 140044872682272
	140044872683280 [label="AddBackward0
------------
alpha: 1"]
	140044872683424 -> 140044872683280
	140044872683424 -> 140044873114224 [dir=none]
	140044873114224 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872683424 -> 140044873137744 [dir=none]
	140044873137744 [label="result1
 (2, 16)" fillcolor=orange]
	140044872683424 -> 140044872712336 [dir=none]
	140044872712336 [label="result2
 (2, 16)" fillcolor=orange]
	140044872683424 -> 140052784847344 [dir=none]
	140052784847344 [label="weight
 (256)" fillcolor=orange]
	140044872683424 [label="NativeGroupNormBackward0
------------------------
C      :            256
HxW    :             25
N      :              2
eps    :          1e-05
group  :             16
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872683472 -> 140044872683424
	140044872683472 -> 140044873114144 [dir=none]
	140044873114144 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872683472 -> 140052784847744 [dir=none]
	140052784847744 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	140044872683472 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872704352 -> 140044872683472
	140044872704352 -> 140044872712256 [dir=none]
	140044872712256 [label="result
 (2, 256, 5, 5)" fillcolor=orange]
	140044872704352 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872704496 -> 140044872704352
	140044872704496 -> 140044873114064 [dir=none]
	140044873114064 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872704496 -> 140044872712816 [dir=none]
	140044872712816 [label="result1
 (2, 16)" fillcolor=orange]
	140044872704496 -> 140044872712576 [dir=none]
	140044872712576 [label="result2
 (2, 16)" fillcolor=orange]
	140044872704496 -> 140052784846144 [dir=none]
	140052784846144 [label="weight
 (256)" fillcolor=orange]
	140044872704496 [label="NativeGroupNormBackward0
------------------------
C      :            256
HxW    :             25
N      :              2
eps    :          1e-05
group  :             16
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872704640 -> 140044872704496
	140044872704640 -> 140044873113984 [dir=none]
	140044873113984 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872704640 -> 140052784847184 [dir=none]
	140052784847184 [label="weight
 (256, 128, 3, 3)" fillcolor=orange]
	140044872704640 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872704832 -> 140044872704640
	140044872704832 -> 140044872712656 [dir=none]
	140044872712656 [label="result
 (2, 128, 10, 10)" fillcolor=orange]
	140044872704832 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872704976 -> 140044872704832
	140044872704976 [label="AddBackward0
------------
alpha: 1"]
	140044872705072 -> 140044872704976
	140044872705072 -> 140044873113904 [dir=none]
	140044873113904 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872705072 -> 140044872712976 [dir=none]
	140044872712976 [label="result1
 (2, 8)" fillcolor=orange]
	140044872705072 -> 140044872713216 [dir=none]
	140044872713216 [label="result2
 (2, 8)" fillcolor=orange]
	140044872705072 -> 140052784845584 [dir=none]
	140052784845584 [label="weight
 (128)" fillcolor=orange]
	140044872705072 [label="NativeGroupNormBackward0
------------------------
C      :            128
HxW    :            100
N      :              2
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872705264 -> 140044872705072
	140044872705264 -> 140044873113664 [dir=none]
	140044873113664 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872705264 -> 140052784845984 [dir=none]
	140052784845984 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	140044872705264 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872705456 -> 140044872705264
	140044872705456 -> 140044872713136 [dir=none]
	140044872713136 [label="result
 (2, 128, 10, 10)" fillcolor=orange]
	140044872705456 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872705600 -> 140044872705456
	140044872705600 -> 140044873113824 [dir=none]
	140044873113824 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872705600 -> 140044872712416 [dir=none]
	140044872712416 [label="result1
 (2, 8)" fillcolor=orange]
	140044872705600 -> 140044872713456 [dir=none]
	140044872713456 [label="result2
 (2, 8)" fillcolor=orange]
	140044872705600 -> 140052785261200 [dir=none]
	140052785261200 [label="weight
 (128)" fillcolor=orange]
	140044872705600 [label="NativeGroupNormBackward0
------------------------
C      :            128
HxW    :            100
N      :              2
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872705744 -> 140044872705600
	140044872705744 -> 140044873113488 [dir=none]
	140044873113488 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872705744 -> 140052784845424 [dir=none]
	140052784845424 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	140044872705744 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872705024 -> 140044872705744
	140044872705024 -> 140044872713376 [dir=none]
	140044872713376 [label="result
 (2, 128, 10, 10)" fillcolor=orange]
	140044872705024 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872706032 -> 140044872705024
	140044872706032 [label="AddBackward0
------------
alpha: 1"]
	140044872706128 -> 140044872706032
	140044872706128 -> 140044873113408 [dir=none]
	140044873113408 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872706128 -> 140044872712736 [dir=none]
	140044872712736 [label="result1
 (2, 8)" fillcolor=orange]
	140044872706128 -> 140044872713696 [dir=none]
	140044872713696 [label="result2
 (2, 8)" fillcolor=orange]
	140044872706128 -> 140052785261680 [dir=none]
	140052785261680 [label="weight
 (128)" fillcolor=orange]
	140044872706128 [label="NativeGroupNormBackward0
------------------------
C      :            128
HxW    :            100
N      :              2
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872706320 -> 140044872706128
	140044872706320 -> 140044873113328 [dir=none]
	140044873113328 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872706320 -> 140052784844944 [dir=none]
	140052784844944 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	140044872706320 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872706512 -> 140044872706320
	140044872706512 -> 140044872713616 [dir=none]
	140044872713616 [label="result
 (2, 128, 10, 10)" fillcolor=orange]
	140044872706512 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872706656 -> 140044872706512
	140044872706656 -> 140044873113248 [dir=none]
	140044873113248 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872706656 -> 140044872712496 [dir=none]
	140044872712496 [label="result1
 (2, 8)" fillcolor=orange]
	140044872706656 -> 140044872713936 [dir=none]
	140044872713936 [label="result2
 (2, 8)" fillcolor=orange]
	140044872706656 -> 140052785260640 [dir=none]
	140052785260640 [label="weight
 (128)" fillcolor=orange]
	140044872706656 [label="NativeGroupNormBackward0
------------------------
C      :            128
HxW    :            100
N      :              2
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872706800 -> 140044872706656
	140044872706800 -> 140044873113168 [dir=none]
	140044873113168 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872706800 -> 140052785262080 [dir=none]
	140052785262080 [label="weight
 (128, 64, 3, 3)" fillcolor=orange]
	140044872706800 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872706992 -> 140044872706800
	140044872706992 -> 140044872713856 [dir=none]
	140044872713856 [label="result
 (2, 64, 19, 19)" fillcolor=orange]
	140044872706992 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872707136 -> 140044872706992
	140044872707136 [label="AddBackward0
------------
alpha: 1"]
	140044872707232 -> 140044872707136
	140044872707232 -> 140044873112928 [dir=none]
	140044873112928 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872707232 -> 140044872714176 [dir=none]
	140044872714176 [label="result1
 (2, 4)" fillcolor=orange]
	140044872707232 -> 140044872714096 [dir=none]
	140044872714096 [label="result2
 (2, 4)" fillcolor=orange]
	140044872707232 -> 140052785260160 [dir=none]
	140052785260160 [label="weight
 (64)" fillcolor=orange]
	140044872707232 [label="NativeGroupNormBackward0
------------------------
C      :             64
HxW    :            361
N      :              2
eps    :          1e-05
group  :              4
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872707424 -> 140044872707232
	140044872707424 -> 140044873112768 [dir=none]
	140044873112768 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872707424 -> 140052785260960 [dir=none]
	140052785260960 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	140044872707424 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872707616 -> 140044872707424
	140044872707616 -> 140044872714016 [dir=none]
	140044872714016 [label="result
 (2, 64, 19, 19)" fillcolor=orange]
	140044872707616 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872707760 -> 140044872707616
	140044872707760 -> 140044873112208 [dir=none]
	140044873112208 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872707760 -> 140044872714416 [dir=none]
	140044872714416 [label="result1
 (2, 4)" fillcolor=orange]
	140044872707760 -> 140044872714336 [dir=none]
	140044872714336 [label="result2
 (2, 4)" fillcolor=orange]
	140044872707760 -> 140052785259600 [dir=none]
	140052785259600 [label="weight
 (64)" fillcolor=orange]
	140044872707760 [label="NativeGroupNormBackward0
------------------------
C      :             64
HxW    :            361
N      :              2
eps    :          1e-05
group  :              4
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872707904 -> 140044872707760
	140044872707904 -> 140044873112528 [dir=none]
	140044873112528 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872707904 -> 140052785260400 [dir=none]
	140052785260400 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	140044872707904 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872707184 -> 140044872707904
	140044872707184 -> 140044872714256 [dir=none]
	140044872714256 [label="result
 (2, 64, 19, 19)" fillcolor=orange]
	140044872707184 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872740928 -> 140044872707184
	140044872740928 [label="AddBackward0
------------
alpha: 1"]
	140044872741120 -> 140044872740928
	140044872741120 -> 140044873111488 [dir=none]
	140044873111488 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872741120 -> 140044872714656 [dir=none]
	140044872714656 [label="result1
 (2, 4)" fillcolor=orange]
	140044872741120 -> 140044872714576 [dir=none]
	140044872714576 [label="result2
 (2, 4)" fillcolor=orange]
	140044872741120 -> 140052785259120 [dir=none]
	140052785259120 [label="weight
 (64)" fillcolor=orange]
	140044872741120 [label="NativeGroupNormBackward0
------------------------
C      :             64
HxW    :            361
N      :              2
eps    :          1e-05
group  :              4
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872741312 -> 140044872741120
	140044872741312 -> 140044873112688 [dir=none]
	140044873112688 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872741312 -> 140052785259920 [dir=none]
	140052785259920 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	140044872741312 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872741504 -> 140044872741312
	140044872741504 -> 140044872714496 [dir=none]
	140044872714496 [label="result
 (2, 64, 19, 19)" fillcolor=orange]
	140044872741504 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872741648 -> 140044872741504
	140044872741648 -> 140044873112368 [dir=none]
	140044873112368 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872741648 -> 140044872714896 [dir=none]
	140044872714896 [label="result1
 (2, 4)" fillcolor=orange]
	140044872741648 -> 140044872714816 [dir=none]
	140044872714816 [label="result2
 (2, 4)" fillcolor=orange]
	140044872741648 -> 140052785259040 [dir=none]
	140052785259040 [label="weight
 (64)" fillcolor=orange]
	140044872741648 [label="NativeGroupNormBackward0
------------------------
C      :             64
HxW    :            361
N      :              2
eps    :          1e-05
group  :              4
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872741792 -> 140044872741648
	140044872741792 -> 140044873113008 [dir=none]
	140044873113008 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872741792 -> 140052785259360 [dir=none]
	140052785259360 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	140044872741792 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872741072 -> 140044872741792
	140044872741072 -> 140044872714736 [dir=none]
	140044872714736 [label="result1
 (2, 64, 19, 19)" fillcolor=orange]
	140044872741072 -> 140044873111168 [dir=none]
	140044873111168 [label="self
 (2, 64, 38, 38)" fillcolor=orange]
	140044872741072 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (3, 3)
padding    :         (1, 1)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	140044872742080 -> 140044872741072
	140044872742080 -> 140044872715056 [dir=none]
	140044872715056 [label="result
 (2, 64, 38, 38)" fillcolor=orange]
	140044872742080 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872742224 -> 140044872742080
	140044872742224 -> 140044873112128 [dir=none]
	140044873112128 [label="input
 (2, 64, 38, 38)" fillcolor=orange]
	140044872742224 -> 140044872713056 [dir=none]
	140044872713056 [label="result1
 (2, 4)" fillcolor=orange]
	140044872742224 -> 140044872713776 [dir=none]
	140044872713776 [label="result2
 (2, 4)" fillcolor=orange]
	140044872742224 -> 140052785090448 [dir=none]
	140052785090448 [label="weight
 (64)" fillcolor=orange]
	140044872742224 [label="NativeGroupNormBackward0
------------------------
C      :             64
HxW    :           1444
N      :              2
eps    :          1e-05
group  :              4
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872742368 -> 140044872742224
	140044872742368 -> 140044873113088 [dir=none]
	140044873113088 [label="input
 (2, 3, 76, 76)" fillcolor=orange]
	140044872742368 -> 140052785137040 [dir=none]
	140052785137040 [label="weight
 (64, 3, 7, 7)" fillcolor=orange]
	140044872742368 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (3, 3)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872742560 -> 140044872742368
	140052785137040 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.0.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	140052785137040 -> 140044872742560
	140044872742560 [label=AccumulateGrad]
	140044872742272 -> 140044872742224
	140052785090448 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.1.weight
 (64)" fillcolor=lightblue]
	140052785090448 -> 140044872742272
	140044872742272 [label=AccumulateGrad]
	140044872741888 -> 140044872742224
	140052785089088 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.1.bias
 (64)" fillcolor=lightblue]
	140052785089088 -> 140044872741888
	140044872741888 [label=AccumulateGrad]
	140044872741984 -> 140044872741792
	140052785259360 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.4.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140052785259360 -> 140044872741984
	140044872741984 [label=AccumulateGrad]
	140044872741696 -> 140044872741648
	140052785259040 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.4.0.bn1.weight
 (64)" fillcolor=lightblue]
	140052785259040 -> 140044872741696
	140044872741696 [label=AccumulateGrad]
	140044872741552 -> 140044872741648
	140052785137120 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.4.0.bn1.bias
 (64)" fillcolor=lightblue]
	140052785137120 -> 140044872741552
	140044872741552 [label=AccumulateGrad]
	140044872741456 -> 140044872741312
	140052785259920 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.4.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140052785259920 -> 140044872741456
	140044872741456 [label=AccumulateGrad]
	140044872741216 -> 140044872741120
	140052785259120 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.4.0.bn2.weight
 (64)" fillcolor=lightblue]
	140052785259120 -> 140044872741216
	140044872741216 [label=AccumulateGrad]
	140044872741168 -> 140044872741120
	140052785259520 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.4.0.bn2.bias
 (64)" fillcolor=lightblue]
	140052785259520 -> 140044872741168
	140044872741168 [label=AccumulateGrad]
	140044872741072 -> 140044872740928
	140044872708048 -> 140044872707904
	140052785260400 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.4.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140052785260400 -> 140044872708048
	140044872708048 [label=AccumulateGrad]
	140044872707808 -> 140044872707760
	140052785259600 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.4.1.bn1.weight
 (64)" fillcolor=lightblue]
	140052785259600 -> 140044872707808
	140044872707808 [label=AccumulateGrad]
	140044872707664 -> 140044872707760
	140052785260080 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.4.1.bn1.bias
 (64)" fillcolor=lightblue]
	140052785260080 -> 140044872707664
	140044872707664 [label=AccumulateGrad]
	140044872707568 -> 140044872707424
	140052785260960 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.4.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140052785260960 -> 140044872707568
	140044872707568 [label=AccumulateGrad]
	140044872707328 -> 140044872707232
	140052785260160 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.4.1.bn2.weight
 (64)" fillcolor=lightblue]
	140052785260160 -> 140044872707328
	140044872707328 [label=AccumulateGrad]
	140044872707280 -> 140044872707232
	140052785260560 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.4.1.bn2.bias
 (64)" fillcolor=lightblue]
	140052785260560 -> 140044872707280
	140044872707280 [label=AccumulateGrad]
	140044872707184 -> 140044872707136
	140044872706944 -> 140044872706800
	140052785262080 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140052785262080 -> 140044872706944
	140044872706944 [label=AccumulateGrad]
	140044872706704 -> 140044872706656
	140052785260640 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.0.bn1.weight
 (128)" fillcolor=lightblue]
	140052785260640 -> 140044872706704
	140044872706704 [label=AccumulateGrad]
	140044872706560 -> 140044872706656
	140052785261120 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.0.bn1.bias
 (128)" fillcolor=lightblue]
	140052785261120 -> 140044872706560
	140044872706560 [label=AccumulateGrad]
	140044872706464 -> 140044872706320
	140052784844944 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140052784844944 -> 140044872706464
	140044872706464 [label=AccumulateGrad]
	140044872706224 -> 140044872706128
	140052785261680 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.0.bn2.weight
 (128)" fillcolor=lightblue]
	140052785261680 -> 140044872706224
	140044872706224 [label=AccumulateGrad]
	140044872706176 -> 140044872706128
	140052785262240 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.0.bn2.bias
 (128)" fillcolor=lightblue]
	140052785262240 -> 140044872706176
	140044872706176 [label=AccumulateGrad]
	140044872706080 -> 140044872706032
	140044872706080 -> 140044873113744 [dir=none]
	140044873113744 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872706080 -> 140044872715136 [dir=none]
	140044872715136 [label="result1
 (2, 8)" fillcolor=orange]
	140044872706080 -> 140044872715216 [dir=none]
	140044872715216 [label="result2
 (2, 8)" fillcolor=orange]
	140044872706080 -> 140052880529984 [dir=none]
	140052880529984 [label="weight
 (128)" fillcolor=orange]
	140044872706080 [label="NativeGroupNormBackward0
------------------------
C      :            128
HxW    :            100
N      :              2
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872706896 -> 140044872706080
	140044872706896 -> 140044873113168 [dir=none]
	140044873113168 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872706896 -> 140052785261360 [dir=none]
	140052785261360 [label="weight
 (128, 64, 1, 1)" fillcolor=orange]
	140044872706896 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872706992 -> 140044872706896
	140044872707040 -> 140044872706896
	140052785261360 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	140052785261360 -> 140044872707040
	140044872707040 [label=AccumulateGrad]
	140044872706416 -> 140044872706080
	140052880529984 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	140052880529984 -> 140044872706416
	140044872706416 [label=AccumulateGrad]
	140044872706368 -> 140044872706080
	140052785262320 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	140052785262320 -> 140044872706368
	140044872706368 [label=AccumulateGrad]
	140044872705936 -> 140044872705744
	140052784845424 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140052784845424 -> 140044872705936
	140044872705936 [label=AccumulateGrad]
	140044872705648 -> 140044872705600
	140052785261200 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.1.bn1.weight
 (128)" fillcolor=lightblue]
	140052785261200 -> 140044872705648
	140044872705648 [label=AccumulateGrad]
	140044872705504 -> 140044872705600
	140052785261600 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.1.bn1.bias
 (128)" fillcolor=lightblue]
	140052785261600 -> 140044872705504
	140044872705504 [label=AccumulateGrad]
	140044872705408 -> 140044872705264
	140052784845984 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140052784845984 -> 140044872705408
	140044872705408 [label=AccumulateGrad]
	140044872705168 -> 140044872705072
	140052784845584 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.1.bn2.weight
 (128)" fillcolor=lightblue]
	140052784845584 -> 140044872705168
	140044872705168 [label=AccumulateGrad]
	140044872705120 -> 140044872705072
	140052784845104 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.5.1.bn2.bias
 (128)" fillcolor=lightblue]
	140052784845104 -> 140044872705120
	140044872705120 [label=AccumulateGrad]
	140044872705024 -> 140044872704976
	140044872704784 -> 140044872704640
	140052784847184 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140052784847184 -> 140044872704784
	140044872704784 [label=AccumulateGrad]
	140044872704544 -> 140044872704496
	140052784846144 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.0.bn1.weight
 (256)" fillcolor=lightblue]
	140052784846144 -> 140044872704544
	140044872704544 [label=AccumulateGrad]
	140044872704400 -> 140044872704496
	140052784845744 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.0.bn1.bias
 (256)" fillcolor=lightblue]
	140052784845744 -> 140044872704400
	140044872704400 [label=AccumulateGrad]
	140044872704304 -> 140044872683472
	140052784847744 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140052784847744 -> 140044872704304
	140044872704304 [label=AccumulateGrad]
	140044872704160 -> 140044872683424
	140052784847344 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.0.bn2.weight
 (256)" fillcolor=lightblue]
	140052784847344 -> 140044872704160
	140044872704160 [label=AccumulateGrad]
	140044872704064 -> 140044872683424
	140052784846944 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.0.bn2.bias
 (256)" fillcolor=lightblue]
	140052784846944 -> 140044872704064
	140044872704064 [label=AccumulateGrad]
	140044872683376 -> 140044872683280
	140044872683376 -> 140044873114464 [dir=none]
	140044873114464 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872683376 -> 140044872714976 [dir=none]
	140044872714976 [label="result1
 (2, 16)" fillcolor=orange]
	140044872683376 -> 140044872715456 [dir=none]
	140044872715456 [label="result2
 (2, 16)" fillcolor=orange]
	140044872683376 -> 140052784847904 [dir=none]
	140052784847904 [label="weight
 (256)" fillcolor=orange]
	140044872683376 [label="NativeGroupNormBackward0
------------------------
C      :            256
HxW    :             25
N      :              2
eps    :          1e-05
group  :             16
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872704736 -> 140044872683376
	140044872704736 -> 140044873113984 [dir=none]
	140044873113984 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872704736 -> 140052784846464 [dir=none]
	140052784846464 [label="weight
 (256, 128, 1, 1)" fillcolor=orange]
	140044872704736 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872704832 -> 140044872704736
	140044872704880 -> 140044872704736
	140052784846464 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140052784846464 -> 140044872704880
	140044872704880 [label=AccumulateGrad]
	140044872704256 -> 140044872683376
	140052784847904 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	140052784847904 -> 140044872704256
	140044872704256 [label=AccumulateGrad]
	140044872704208 -> 140044872683376
	140052784847504 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	140052784847504 -> 140044872704208
	140044872704208 [label=AccumulateGrad]
	140044872683184 -> 140044872682992
	140052784848224 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140052784848224 -> 140044872683184
	140044872683184 [label=AccumulateGrad]
	140044872682896 -> 140044872682848
	140052784846704 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.1.bn1.weight
 (256)" fillcolor=lightblue]
	140052784846704 -> 140044872682896
	140044872682896 [label=AccumulateGrad]
	140044872682752 -> 140044872682848
	140052784846384 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.1.bn1.bias
 (256)" fillcolor=lightblue]
	140052784846384 -> 140044872682752
	140044872682752 [label=AccumulateGrad]
	140044872682656 -> 140044872682512
	140052784848784 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140052784848784 -> 140044872682656
	140044872682656 [label=AccumulateGrad]
	140044872682416 -> 140044872682320
	140052784848384 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.1.bn2.weight
 (256)" fillcolor=lightblue]
	140052784848384 -> 140044872682416
	140044872682416 [label=AccumulateGrad]
	140044872682368 -> 140044872682320
	140052784846864 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.6.1.bn2.bias
 (256)" fillcolor=lightblue]
	140052784846864 -> 140044872682368
	140044872682368 [label=AccumulateGrad]
	140044872682272 -> 140044872682224
	140044872682032 -> 140044872681888
	140052784923808 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	140052784923808 -> 140044872682032
	140044872682032 [label=AccumulateGrad]
	140044872681792 -> 140044872681744
	140052784848464 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.0.bn1.weight
 (512)" fillcolor=lightblue]
	140052784848464 -> 140044872681792
	140044872681792 [label=AccumulateGrad]
	140044872681648 -> 140044872681744
	140052784848544 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.0.bn1.bias
 (512)" fillcolor=lightblue]
	140052784848544 -> 140044872681648
	140044872681648 [label=AccumulateGrad]
	140044872681552 -> 140044872681408
	140052784924368 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140052784924368 -> 140044872681552
	140044872681552 [label=AccumulateGrad]
	140044872681312 -> 140044872681216
	140052784923968 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.0.bn2.weight
 (512)" fillcolor=lightblue]
	140052784923968 -> 140044872681312
	140044872681312 [label=AccumulateGrad]
	140044872681264 -> 140044872681216
	140052784923568 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.0.bn2.bias
 (512)" fillcolor=lightblue]
	140052784923568 -> 140044872681264
	140044872681264 [label=AccumulateGrad]
	140044872681168 -> 140044872681120
	140044872681168 -> 140044873115184 [dir=none]
	140044873115184 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872681168 -> 140044872715696 [dir=none]
	140044872715696 [label="result1
 (2, 32)" fillcolor=orange]
	140044872681168 -> 140044872713536 [dir=none]
	140044872713536 [label="result2
 (2, 32)" fillcolor=orange]
	140044872681168 -> 140052784924528 [dir=none]
	140052784924528 [label="weight
 (512)" fillcolor=orange]
	140044872681168 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              9
N      :              2
eps    :          1e-05
group  :             32
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872681984 -> 140044872681168
	140044872681984 -> 140044873114704 [dir=none]
	140044873114704 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872681984 -> 140052784923088 [dir=none]
	140052784923088 [label="weight
 (512, 256, 1, 1)" fillcolor=orange]
	140044872681984 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872682080 -> 140044872681984
	140044872682128 -> 140044872681984
	140052784923088 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140052784923088 -> 140044872682128
	140044872682128 [label=AccumulateGrad]
	140044872681504 -> 140044872681168
	140052784924528 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	140052784924528 -> 140044872681504
	140044872681504 [label=AccumulateGrad]
	140044872681456 -> 140044872681168
	140052784924128 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	140052784924128 -> 140044872681456
	140044872681456 [label=AccumulateGrad]
	140044872681024 -> 140044872680832
	140052784924848 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140052784924848 -> 140044872681024
	140044872681024 [label=AccumulateGrad]
	140044872680736 -> 140044872680688
	140052784923328 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.1.bn1.weight
 (512)" fillcolor=lightblue]
	140052784923328 -> 140044872680736
	140044872680736 [label=AccumulateGrad]
	140044872680592 -> 140044872680688
	140052784923008 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.1.bn1.bias
 (512)" fillcolor=lightblue]
	140052784923008 -> 140044872680592
	140044872680592 [label=AccumulateGrad]
	140044872680496 -> 140044872680352
	140052784925408 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140052784925408 -> 140044872680496
	140044872680496 [label=AccumulateGrad]
	140044872680256 -> 140044872680160
	140052784925008 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.1.bn2.weight
 (512)" fillcolor=lightblue]
	140052784925008 -> 140044872680256
	140044872680256 [label=AccumulateGrad]
	140044872680208 -> 140044872680160
	140052784923488 [label="obs_encoder.obs_nets.agentview_image.backbone.nets.7.1.bn2.bias
 (512)" fillcolor=lightblue]
	140052784923488 -> 140044872680208
	140044872680208 [label=AccumulateGrad]
	140044872680112 -> 140044872680064
	140044872679728 -> 140044872679680
	140052784925808 [label="obs_encoder.obs_nets.agentview_image.pool.nets.weight
 (32, 512, 1, 1)" fillcolor=lightblue]
	140052784925808 -> 140044872679728
	140044872679728 [label=AccumulateGrad]
	140044872679488 -> 140044872679680
	140052784925648 [label="obs_encoder.obs_nets.agentview_image.pool.nets.bias
 (32)" fillcolor=lightblue]
	140052784925648 -> 140044872679488
	140044872679488 [label=AccumulateGrad]
	140044872650368 -> 140044872650320
	140044872650368 [label="SumBackward1
-------------------
dim       :    (1,)
keepdim   :    True
self_sizes: (64, 9)"]
	140044872650464 -> 140044872650368
	140044872650464 -> 140052784925728 [dir=none]
	140052784925728 [label="self
 (1, 9)" fillcolor=orange]
	140044872650464 [label="MulBackward0
---------------------
other:           None
self : [saved tensor]"]
	140044872650656 -> 140044872650464
	140044872649696 -> 140044872649840
	140044872649696 [label=TBackward0]
	140044872650272 -> 140044872649696
	140052784926208 [label="obs_encoder.obs_nets.agentview_image.nets.3.weight
 (64, 64)" fillcolor=lightblue]
	140052784926208 -> 140044872650272
	140044872650272 [label=AccumulateGrad]
	140044872649216 -> 140044872649552
	140044872649216 [label="ReshapeAliasBackward0
---------------------
self_sizes: (2, 64)"]
	140044872649984 -> 140044872649216
	140044872649984 -> 140044872715376 [dir=none]
	140044872715376 [label="result
 (2, 64)" fillcolor=orange]
	140044872649984 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872650608 -> 140044872649984
	140044872650608 -> 140044873116624 [dir=none]
	140044873116624 [label="mat1
 (2, 64)" fillcolor=orange]
	140044872650608 -> 140044872715536 [dir=none]
	140044872715536 [label="mat2
 (64, 64)" fillcolor=orange]
	140044872650608 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :        (2, 64)
mat1_strides:        (64, 1)
mat2        : [saved tensor]
mat2_sizes  :       (64, 64)
mat2_strides:        (1, 64)"]
	140044872650080 -> 140044872650608
	140052785107568 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.nets.3.bias
 (64)" fillcolor=lightblue]
	140052785107568 -> 140044872650080
	140044872650080 [label=AccumulateGrad]
	140044872650128 -> 140044872650608
	140044872650128 [label="ReshapeAliasBackward0
----------------------
self_sizes: (2, 32, 2)"]
	140044872679632 -> 140044872650128
	140044872679632 [label="AsStridedBackward0
--------------------------
size          : (2, 32, 2)
storage_offset:          0
stride        : (64, 2, 1)"]
	140044872679968 -> 140044872679632
	140044872679968 [label=CopySlices]
	140044872680448 -> 140044872679968
	140044872680448 [label="CatBackward0
------------
dim: 1"]
	140044872680880 -> 140044872680448
	140044872680880 [label="SumBackward1
-------------------
dim       :    (1,)
keepdim   :    True
self_sizes: (64, 9)"]
	140044872680928 -> 140044872680880
	140044872680928 -> 140052785110048 [dir=none]
	140052785110048 [label="self
 (1, 9)" fillcolor=orange]
	140044872680928 [label="MulBackward0
---------------------
other:           None
self : [saved tensor]"]
	140044872682560 -> 140044872680928
	140044872682560 -> 140044872715616 [dir=none]
	140044872715616 [label="result
 (64, 9)" fillcolor=orange]
	140044872682560 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	140044872682176 -> 140044872682560
	140044872682176 -> 140043446880192 [dir=none]
	140043446880192 [label="other
 (1)" fillcolor=orange]
	140044872682176 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	140044872683136 -> 140044872682176
	140044872683136 [label="ReshapeAliasBackward0
-------------------------
self_sizes: (2, 32, 3, 3)"]
	140044872682800 -> 140044872683136
	140044872682800 -> 140044873119200 [dir=none]
	140044873119200 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872682800 -> 140052785110128 [dir=none]
	140052785110128 [label="weight
 (32, 512, 1, 1)" fillcolor=orange]
	140044872682800 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:          (32,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872683232 -> 140044872682800
	140044872683232 -> 140044872713296 [dir=none]
	140044872713296 [label="result
 (2, 512, 3, 3)" fillcolor=orange]
	140044872683232 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872704928 -> 140044872683232
	140044872704928 [label="AddBackward0
------------
alpha: 1"]
	140044872705888 -> 140044872704928
	140044872705888 -> 140044873119120 [dir=none]
	140044873119120 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872705888 -> 140044872715776 [dir=none]
	140044872715776 [label="result1
 (2, 32)" fillcolor=orange]
	140044872705888 -> 140044872716016 [dir=none]
	140044872716016 [label="result2
 (2, 32)" fillcolor=orange]
	140044872705888 -> 140052785110688 [dir=none]
	140052785110688 [label="weight
 (512)" fillcolor=orange]
	140044872705888 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              9
N      :              2
eps    :          1e-05
group  :             32
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872706848 -> 140044872705888
	140044872706848 -> 140044873118880 [dir=none]
	140044873118880 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872706848 -> 140052785108128 [dir=none]
	140052785108128 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	140044872706848 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872707520 -> 140044872706848
	140044872707520 -> 140044872716176 [dir=none]
	140044872716176 [label="result
 (2, 512, 3, 3)" fillcolor=orange]
	140044872707520 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872708000 -> 140044872707520
	140044872708000 -> 140044873119040 [dir=none]
	140044873119040 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872708000 -> 140044872715936 [dir=none]
	140044872715936 [label="result1
 (2, 32)" fillcolor=orange]
	140044872708000 -> 140044872715296 [dir=none]
	140044872715296 [label="result2
 (2, 32)" fillcolor=orange]
	140044872708000 -> 140052779891504 [dir=none]
	140052779891504 [label="weight
 (512)" fillcolor=orange]
	140044872708000 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              9
N      :              2
eps    :          1e-05
group  :             32
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872707712 -> 140044872708000
	140044872707712 -> 140044873118800 [dir=none]
	140044873118800 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872707712 -> 140052785110528 [dir=none]
	140052785110528 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	140044872707712 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872704448 -> 140044872707712
	140044872704448 -> 140044872715856 [dir=none]
	140044872715856 [label="result
 (2, 512, 3, 3)" fillcolor=orange]
	140044872704448 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872741840 -> 140044872704448
	140044872741840 [label="AddBackward0
------------
alpha: 1"]
	140044872742416 -> 140044872741840
	140044872742416 -> 140044873118720 [dir=none]
	140044873118720 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872742416 -> 140044872712896 [dir=none]
	140044872712896 [label="result1
 (2, 32)" fillcolor=orange]
	140044872742416 -> 140044872716096 [dir=none]
	140044872716096 [label="result2
 (2, 32)" fillcolor=orange]
	140044872742416 -> 140052779889744 [dir=none]
	140052779889744 [label="weight
 (512)" fillcolor=orange]
	140044872742416 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              9
N      :              2
eps    :          1e-05
group  :             32
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872742512 -> 140044872742416
	140044872742512 -> 140044873118640 [dir=none]
	140044873118640 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872742512 -> 140052779984272 [dir=none]
	140052779984272 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	140044872742512 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872742704 -> 140044872742512
	140044872742704 -> 140044872826944 [dir=none]
	140044872826944 [label="result
 (2, 512, 3, 3)" fillcolor=orange]
	140044872742704 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872742848 -> 140044872742704
	140044872742848 -> 140044873118560 [dir=none]
	140044873118560 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872742848 -> 140044872827264 [dir=none]
	140044872827264 [label="result1
 (2, 32)" fillcolor=orange]
	140044872742848 -> 140044872827024 [dir=none]
	140044872827024 [label="result2
 (2, 32)" fillcolor=orange]
	140044872742848 -> 140052779892464 [dir=none]
	140052779892464 [label="weight
 (512)" fillcolor=orange]
	140044872742848 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              9
N      :              2
eps    :          1e-05
group  :             32
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872742944 -> 140044872742848
	140044872742944 -> 140044873118480 [dir=none]
	140044873118480 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872742944 -> 140052779983712 [dir=none]
	140052779983712 [label="weight
 (512, 256, 3, 3)" fillcolor=orange]
	140044872742944 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872743184 -> 140044872742944
	140044872743184 -> 140044872827184 [dir=none]
	140044872827184 [label="result
 (2, 256, 5, 5)" fillcolor=orange]
	140044872743184 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872743328 -> 140044872743184
	140044872743328 [label="AddBackward0
------------
alpha: 1"]
	140044872743424 -> 140044872743328
	140044872743424 -> 140044873118400 [dir=none]
	140044873118400 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872743424 -> 140044872827664 [dir=none]
	140044872827664 [label="result1
 (2, 16)" fillcolor=orange]
	140044872743424 -> 140044872827424 [dir=none]
	140044872827424 [label="result2
 (2, 16)" fillcolor=orange]
	140044872743424 -> 140052779891904 [dir=none]
	140052779891904 [label="weight
 (256)" fillcolor=orange]
	140044872743424 [label="NativeGroupNormBackward0
------------------------
C      :            256
HxW    :             25
N      :              2
eps    :          1e-05
group  :             16
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872743568 -> 140044872743424
	140044872743568 -> 140044873118160 [dir=none]
	140044873118160 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872743568 -> 140052779892304 [dir=none]
	140052779892304 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	140044872743568 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872743760 -> 140044872743568
	140044872743760 -> 140044872827584 [dir=none]
	140044872827584 [label="result
 (2, 256, 5, 5)" fillcolor=orange]
	140044872743760 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872743904 -> 140044872743760
	140044872743904 -> 140044873118320 [dir=none]
	140044873118320 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872743904 -> 140044872828064 [dir=none]
	140044872828064 [label="result1
 (2, 16)" fillcolor=orange]
	140044872743904 -> 140044872827824 [dir=none]
	140044872827824 [label="result2
 (2, 16)" fillcolor=orange]
	140044872743904 -> 140052779890224 [dir=none]
	140052779890224 [label="weight
 (256)" fillcolor=orange]
	140044872743904 [label="NativeGroupNormBackward0
------------------------
C      :            256
HxW    :             25
N      :              2
eps    :          1e-05
group  :             16
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872744000 -> 140044872743904
	140044872744000 -> 140044873118080 [dir=none]
	140044873118080 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872744000 -> 140052779891744 [dir=none]
	140052779891744 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	140044872744000 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872743376 -> 140044872744000
	140044872743376 -> 140044872827984 [dir=none]
	140044872827984 [label="result
 (2, 256, 5, 5)" fillcolor=orange]
	140044872743376 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872744288 -> 140044872743376
	140044872744288 [label="AddBackward0
------------
alpha: 1"]
	140044872744384 -> 140044872744288
	140044872744384 -> 140044873118000 [dir=none]
	140044873118000 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872744384 -> 140044872828304 [dir=none]
	140044872828304 [label="result1
 (2, 16)" fillcolor=orange]
	140044872744384 -> 140044872827104 [dir=none]
	140044872827104 [label="result2
 (2, 16)" fillcolor=orange]
	140044872744384 -> 140052779890864 [dir=none]
	140052779890864 [label="weight
 (256)" fillcolor=orange]
	140044872744384 [label="NativeGroupNormBackward0
------------------------
C      :            256
HxW    :             25
N      :              2
eps    :          1e-05
group  :             16
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872744528 -> 140044872744384
	140044872744528 -> 140044873117920 [dir=none]
	140044873117920 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872744528 -> 140052779891264 [dir=none]
	140052779891264 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	140044872744528 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872744720 -> 140044872744528
	140044872744720 -> 140044872828224 [dir=none]
	140044872828224 [label="result
 (2, 256, 5, 5)" fillcolor=orange]
	140044872744720 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872744864 -> 140044872744720
	140044872744864 -> 140044873117840 [dir=none]
	140044873117840 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872744864 -> 140044872828544 [dir=none]
	140044872828544 [label="result1
 (2, 16)" fillcolor=orange]
	140044872744864 -> 140044872827504 [dir=none]
	140044872827504 [label="result2
 (2, 16)" fillcolor=orange]
	140044872744864 -> 140052779889664 [dir=none]
	140052779889664 [label="weight
 (256)" fillcolor=orange]
	140044872744864 [label="NativeGroupNormBackward0
------------------------
C      :            256
HxW    :             25
N      :              2
eps    :          1e-05
group  :             16
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872744912 -> 140044872744864
	140044872744912 -> 140044873117760 [dir=none]
	140044873117760 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872744912 -> 140052779890704 [dir=none]
	140052779890704 [label="weight
 (256, 128, 3, 3)" fillcolor=orange]
	140044872744912 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872839424 -> 140044872744912
	140044872839424 -> 140044872828384 [dir=none]
	140044872828384 [label="result
 (2, 128, 10, 10)" fillcolor=orange]
	140044872839424 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872839568 -> 140044872839424
	140044872839568 [label="AddBackward0
------------
alpha: 1"]
	140044872839664 -> 140044872839568
	140044872839664 -> 140044873117584 [dir=none]
	140044873117584 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872839664 -> 140044872827904 [dir=none]
	140044872827904 [label="result1
 (2, 8)" fillcolor=orange]
	140044872839664 -> 140044872828784 [dir=none]
	140044872828784 [label="result2
 (2, 8)" fillcolor=orange]
	140044872839664 -> 140052779889104 [dir=none]
	140052779889104 [label="weight
 (128)" fillcolor=orange]
	140044872839664 [label="NativeGroupNormBackward0
------------------------
C      :            128
HxW    :            100
N      :              2
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872839808 -> 140044872839664
	140044872839808 -> 140044873117344 [dir=none]
	140044873117344 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872839808 -> 140052779889504 [dir=none]
	140052779889504 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	140044872839808 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872840000 -> 140044872839808
	140044872840000 -> 140044872828704 [dir=none]
	140044872828704 [label="result
 (2, 128, 10, 10)" fillcolor=orange]
	140044872840000 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872840144 -> 140044872840000
	140044872840144 -> 140044873117504 [dir=none]
	140044873117504 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872840144 -> 140044872828144 [dir=none]
	140044872828144 [label="result1
 (2, 8)" fillcolor=orange]
	140044872840144 -> 140044872829024 [dir=none]
	140044872829024 [label="result2
 (2, 8)" fillcolor=orange]
	140044872840144 -> 140052785052384 [dir=none]
	140052785052384 [label="weight
 (128)" fillcolor=orange]
	140044872840144 [label="NativeGroupNormBackward0
------------------------
C      :            128
HxW    :            100
N      :              2
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872840240 -> 140044872840144
	140044872840240 -> 140044873117264 [dir=none]
	140044873117264 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872840240 -> 140052779888944 [dir=none]
	140052779888944 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	140044872840240 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872839616 -> 140044872840240
	140044872839616 -> 140044872828944 [dir=none]
	140044872828944 [label="result
 (2, 128, 10, 10)" fillcolor=orange]
	140044872839616 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872840528 -> 140044872839616
	140044872840528 [label="AddBackward0
------------
alpha: 1"]
	140044872840624 -> 140044872840528
	140044872840624 -> 140044873117184 [dir=none]
	140044873117184 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872840624 -> 140044872828464 [dir=none]
	140044872828464 [label="result1
 (2, 8)" fillcolor=orange]
	140044872840624 -> 140044872829264 [dir=none]
	140044872829264 [label="result2
 (2, 8)" fillcolor=orange]
	140044872840624 -> 140052785053024 [dir=none]
	140052785053024 [label="weight
 (128)" fillcolor=orange]
	140044872840624 [label="NativeGroupNormBackward0
------------------------
C      :            128
HxW    :            100
N      :              2
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872840768 -> 140044872840624
	140044872840768 -> 140044873117104 [dir=none]
	140044873117104 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872840768 -> 140052785053424 [dir=none]
	140052785053424 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	140044872840768 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872840960 -> 140044872840768
	140044872840960 -> 140044872829184 [dir=none]
	140044872829184 [label="result
 (2, 128, 10, 10)" fillcolor=orange]
	140044872840960 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872841104 -> 140044872840960
	140044872841104 -> 140044873117024 [dir=none]
	140044873117024 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872841104 -> 140044872827744 [dir=none]
	140044872827744 [label="result1
 (2, 8)" fillcolor=orange]
	140044872841104 -> 140044872829504 [dir=none]
	140044872829504 [label="result2
 (2, 8)" fillcolor=orange]
	140044872841104 -> 140052785051824 [dir=none]
	140052785051824 [label="weight
 (128)" fillcolor=orange]
	140044872841104 [label="NativeGroupNormBackward0
------------------------
C      :            128
HxW    :            100
N      :              2
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872841200 -> 140044872841104
	140044872841200 -> 140044873116944 [dir=none]
	140044873116944 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872841200 -> 140052785052864 [dir=none]
	140052785052864 [label="weight
 (128, 64, 3, 3)" fillcolor=orange]
	140044872841200 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872841392 -> 140044872841200
	140044872841392 -> 140044872829424 [dir=none]
	140044872829424 [label="result
 (2, 64, 19, 19)" fillcolor=orange]
	140044872841392 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872841536 -> 140044872841392
	140044872841536 [label="AddBackward0
------------
alpha: 1"]
	140044872841632 -> 140044872841536
	140044872841632 -> 140044873116384 [dir=none]
	140044873116384 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872841632 -> 140044872829744 [dir=none]
	140044872829744 [label="result1
 (2, 4)" fillcolor=orange]
	140044872841632 -> 140044872829664 [dir=none]
	140044872829664 [label="result2
 (2, 4)" fillcolor=orange]
	140044872841632 -> 140052785051264 [dir=none]
	140052785051264 [label="weight
 (64)" fillcolor=orange]
	140044872841632 [label="NativeGroupNormBackward0
------------------------
C      :             64
HxW    :            361
N      :              2
eps    :          1e-05
group  :              4
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872841776 -> 140044872841632
	140044872841776 -> 140044873116544 [dir=none]
	140044873116544 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872841776 -> 140052785051664 [dir=none]
	140052785051664 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	140044872841776 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872841968 -> 140044872841776
	140044872841968 -> 140044872829584 [dir=none]
	140044872829584 [label="result
 (2, 64, 19, 19)" fillcolor=orange]
	140044872841968 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872842112 -> 140044872841968
	140044872842112 -> 140044873115584 [dir=none]
	140044873115584 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872842112 -> 140044872829984 [dir=none]
	140044872829984 [label="result1
 (2, 4)" fillcolor=orange]
	140044872842112 -> 140044872829904 [dir=none]
	140044872829904 [label="result2
 (2, 4)" fillcolor=orange]
	140044872842112 -> 140052785050784 [dir=none]
	140052785050784 [label="weight
 (64)" fillcolor=orange]
	140044872842112 [label="NativeGroupNormBackward0
------------------------
C      :             64
HxW    :            361
N      :              2
eps    :          1e-05
group  :              4
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872842208 -> 140044872842112
	140044872842208 -> 140044873116304 [dir=none]
	140044873116304 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872842208 -> 140052785051104 [dir=none]
	140052785051104 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	140044872842208 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872841584 -> 140044872842208
	140044872841584 -> 140044872829824 [dir=none]
	140044872829824 [label="result
 (2, 64, 19, 19)" fillcolor=orange]
	140044872841584 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872842496 -> 140044872841584
	140044872842496 [label="AddBackward0
------------
alpha: 1"]
	140044872842592 -> 140044872842496
	140044872842592 -> 140044873116224 [dir=none]
	140044873116224 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872842592 -> 140044872830224 [dir=none]
	140044872830224 [label="result1
 (2, 4)" fillcolor=orange]
	140044872842592 -> 140044872830144 [dir=none]
	140044872830144 [label="result2
 (2, 4)" fillcolor=orange]
	140044872842592 -> 140052785049824 [dir=none]
	140052785049824 [label="weight
 (64)" fillcolor=orange]
	140044872842592 [label="NativeGroupNormBackward0
------------------------
C      :             64
HxW    :            361
N      :              2
eps    :          1e-05
group  :              4
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872842736 -> 140044872842592
	140044872842736 -> 140044873116464 [dir=none]
	140044873116464 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872842736 -> 140052785050624 [dir=none]
	140052785050624 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	140044872842736 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872842928 -> 140044872842736
	140044872842928 -> 140044872830064 [dir=none]
	140044872830064 [label="result
 (2, 64, 19, 19)" fillcolor=orange]
	140044872842928 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872843072 -> 140044872842928
	140044872843072 -> 140044873116144 [dir=none]
	140044873116144 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872843072 -> 140044872830464 [dir=none]
	140044872830464 [label="result1
 (2, 4)" fillcolor=orange]
	140044872843072 -> 140044872830384 [dir=none]
	140044872830384 [label="result2
 (2, 4)" fillcolor=orange]
	140044872843072 -> 140052784926528 [dir=none]
	140052784926528 [label="weight
 (64)" fillcolor=orange]
	140044872843072 [label="NativeGroupNormBackward0
------------------------
C      :             64
HxW    :            361
N      :              2
eps    :          1e-05
group  :              4
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872843168 -> 140044872843072
	140044872843168 -> 140044873116784 [dir=none]
	140044873116784 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872843168 -> 140052785050064 [dir=none]
	140052785050064 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	140044872843168 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (1, 1)
stride        :         (1, 1)
transposed    :          False
weight        : [saved tensor]"]
	140044872842544 -> 140044872843168
	140044872842544 -> 140044872830304 [dir=none]
	140044872830304 [label="result1
 (2, 64, 19, 19)" fillcolor=orange]
	140044872842544 -> 140044873115664 [dir=none]
	140044873115664 [label="self
 (2, 64, 38, 38)" fillcolor=orange]
	140044872842544 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (3, 3)
padding    :         (1, 1)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	140044872872192 -> 140044872842544
	140044872872192 -> 140044872830624 [dir=none]
	140044872830624 [label="result
 (2, 64, 38, 38)" fillcolor=orange]
	140044872872192 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140044872872288 -> 140044872872192
	140044872872288 -> 140044873116704 [dir=none]
	140044873116704 [label="input
 (2, 64, 38, 38)" fillcolor=orange]
	140044872872288 -> 140044872828624 [dir=none]
	140044872828624 [label="result1
 (2, 4)" fillcolor=orange]
	140044872872288 -> 140044872829344 [dir=none]
	140044872829344 [label="result2
 (2, 4)" fillcolor=orange]
	140044872872288 -> 140052784925568 [dir=none]
	140052784925568 [label="weight
 (64)" fillcolor=orange]
	140044872872288 [label="NativeGroupNormBackward0
------------------------
C      :             64
HxW    :           1444
N      :              2
eps    :          1e-05
group  :              4
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872872384 -> 140044872872288
	140044872872384 -> 140044873116864 [dir=none]
	140044873116864 [label="input
 (2, 3, 76, 76)" fillcolor=orange]
	140044872872384 -> 140052784926368 [dir=none]
	140052784926368 [label="weight
 (64, 3, 7, 7)" fillcolor=orange]
	140044872872384 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (3, 3)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872872576 -> 140044872872384
	140052784926368 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.0.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	140052784926368 -> 140044872872576
	140044872872576 [label=AccumulateGrad]
	140044872872336 -> 140044872872288
	140052784925568 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.1.weight
 (64)" fillcolor=lightblue]
	140052784925568 -> 140044872872336
	140044872872336 [label=AccumulateGrad]
	140044872872096 -> 140044872872288
	140052784925168 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.1.bias
 (64)" fillcolor=lightblue]
	140052784925168 -> 140044872872096
	140044872872096 [label=AccumulateGrad]
	140044872872000 -> 140044872843168
	140052785050064 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.4.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140052785050064 -> 140044872872000
	140044872872000 [label=AccumulateGrad]
	140044872843120 -> 140044872843072
	140052784926528 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.4.0.bn1.weight
 (64)" fillcolor=lightblue]
	140052784926528 -> 140044872843120
	140044872843120 [label=AccumulateGrad]
	140044872842976 -> 140044872843072
	140052784926288 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.4.0.bn1.bias
 (64)" fillcolor=lightblue]
	140052784926288 -> 140044872842976
	140044872842976 [label=AccumulateGrad]
	140044872842880 -> 140044872842736
	140052785050624 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.4.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140052785050624 -> 140044872842880
	140044872842880 [label=AccumulateGrad]
	140044872842688 -> 140044872842592
	140052785049824 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.4.0.bn2.weight
 (64)" fillcolor=lightblue]
	140052785049824 -> 140044872842688
	140044872842688 [label=AccumulateGrad]
	140044872842640 -> 140044872842592
	140052784926608 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.4.0.bn2.bias
 (64)" fillcolor=lightblue]
	140052784926608 -> 140044872842640
	140044872842640 [label=AccumulateGrad]
	140044872842544 -> 140044872842496
	140044872842400 -> 140044872842208
	140052785051104 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.4.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140052785051104 -> 140044872842400
	140044872842400 [label=AccumulateGrad]
	140044872842160 -> 140044872842112
	140052785050784 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.4.1.bn1.weight
 (64)" fillcolor=lightblue]
	140052785050784 -> 140044872842160
	140044872842160 [label=AccumulateGrad]
	140044872842016 -> 140044872842112
	140052785050384 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.4.1.bn1.bias
 (64)" fillcolor=lightblue]
	140052785050384 -> 140044872842016
	140044872842016 [label=AccumulateGrad]
	140044872841920 -> 140044872841776
	140052785051664 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.4.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140052785051664 -> 140044872841920
	140044872841920 [label=AccumulateGrad]
	140044872841728 -> 140044872841632
	140052785051264 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.4.1.bn2.weight
 (64)" fillcolor=lightblue]
	140052785051264 -> 140044872841728
	140044872841728 [label=AccumulateGrad]
	140044872841680 -> 140044872841632
	140052785049744 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.4.1.bn2.bias
 (64)" fillcolor=lightblue]
	140052785049744 -> 140044872841680
	140044872841680 [label=AccumulateGrad]
	140044872841584 -> 140044872841536
	140044872841344 -> 140044872841200
	140052785052864 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140052785052864 -> 140044872841344
	140044872841344 [label=AccumulateGrad]
	140044872841152 -> 140044872841104
	140052785051824 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.0.bn1.weight
 (128)" fillcolor=lightblue]
	140052785051824 -> 140044872841152
	140044872841152 [label=AccumulateGrad]
	140044872841008 -> 140044872841104
	140052785051424 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.0.bn1.bias
 (128)" fillcolor=lightblue]
	140052785051424 -> 140044872841008
	140044872841008 [label=AccumulateGrad]
	140044872840912 -> 140044872840768
	140052785053424 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140052785053424 -> 140044872840912
	140044872840912 [label=AccumulateGrad]
	140044872840720 -> 140044872840624
	140052785053024 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.0.bn2.weight
 (128)" fillcolor=lightblue]
	140052785053024 -> 140044872840720
	140044872840720 [label=AccumulateGrad]
	140044872840672 -> 140044872840624
	140052785052624 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.0.bn2.bias
 (128)" fillcolor=lightblue]
	140052785052624 -> 140044872840672
	140044872840672 [label=AccumulateGrad]
	140044872840576 -> 140044872840528
	140044872840576 -> 140044873117424 [dir=none]
	140044873117424 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872840576 -> 140044872830704 [dir=none]
	140044872830704 [label="result1
 (2, 8)" fillcolor=orange]
	140044872840576 -> 140044872830784 [dir=none]
	140044872830784 [label="result2
 (2, 8)" fillcolor=orange]
	140044872840576 -> 140052785053584 [dir=none]
	140052785053584 [label="weight
 (128)" fillcolor=orange]
	140044872840576 [label="NativeGroupNormBackward0
------------------------
C      :            128
HxW    :            100
N      :              2
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872841296 -> 140044872840576
	140044872841296 -> 140044873116944 [dir=none]
	140044873116944 [label="input
 (2, 64, 19, 19)" fillcolor=orange]
	140044872841296 -> 140052785052144 [dir=none]
	140052785052144 [label="weight
 (128, 64, 1, 1)" fillcolor=orange]
	140044872841296 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872841392 -> 140044872841296
	140044872841440 -> 140044872841296
	140052785052144 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	140052785052144 -> 140044872841440
	140044872841440 [label=AccumulateGrad]
	140044872840864 -> 140044872840576
	140052785053584 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	140052785053584 -> 140044872840864
	140044872840864 [label=AccumulateGrad]
	140044872840816 -> 140044872840576
	140052785053184 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	140052785053184 -> 140044872840816
	140044872840816 [label=AccumulateGrad]
	140044872840432 -> 140044872840240
	140052779888944 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140052779888944 -> 140044872840432
	140044872840432 [label=AccumulateGrad]
	140044872840192 -> 140044872840144
	140052785052384 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.1.bn1.weight
 (128)" fillcolor=lightblue]
	140052785052384 -> 140044872840192
	140044872840192 [label=AccumulateGrad]
	140044872840048 -> 140044872840144
	140052785052064 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.1.bn1.bias
 (128)" fillcolor=lightblue]
	140052785052064 -> 140044872840048
	140044872840048 [label=AccumulateGrad]
	140044872839952 -> 140044872839808
	140052779889504 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140052779889504 -> 140044872839952
	140044872839952 [label=AccumulateGrad]
	140044872839760 -> 140044872839664
	140052779889104 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.1.bn2.weight
 (128)" fillcolor=lightblue]
	140052779889104 -> 140044872839760
	140044872839760 [label=AccumulateGrad]
	140044872839712 -> 140044872839664
	140052785052544 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.5.1.bn2.bias
 (128)" fillcolor=lightblue]
	140052785052544 -> 140044872839712
	140044872839712 [label=AccumulateGrad]
	140044872839616 -> 140044872839568
	140044872839376 -> 140044872744912
	140052779890704 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140052779890704 -> 140044872839376
	140044872839376 [label=AccumulateGrad]
	140044872744768 -> 140044872744864
	140052779889664 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.0.bn1.weight
 (256)" fillcolor=lightblue]
	140052779889664 -> 140044872744768
	140044872744768 [label=AccumulateGrad]
	140044872839232 -> 140044872744864
	140052779889264 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.0.bn1.bias
 (256)" fillcolor=lightblue]
	140052779889264 -> 140044872839232
	140044872839232 [label=AccumulateGrad]
	140044872744672 -> 140044872744528
	140052779891264 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140052779891264 -> 140044872744672
	140044872744672 [label=AccumulateGrad]
	140044872744480 -> 140044872744384
	140052779890864 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.0.bn2.weight
 (256)" fillcolor=lightblue]
	140052779890864 -> 140044872744480
	140044872744480 [label=AccumulateGrad]
	140044872744432 -> 140044872744384
	140052779890464 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.0.bn2.bias
 (256)" fillcolor=lightblue]
	140052779890464 -> 140044872744432
	140044872744432 [label=AccumulateGrad]
	140044872744336 -> 140044872744288
	140044872744336 -> 140044873118240 [dir=none]
	140044873118240 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872744336 -> 140044872830544 [dir=none]
	140044872830544 [label="result1
 (2, 16)" fillcolor=orange]
	140044872744336 -> 140044872830864 [dir=none]
	140044872830864 [label="result2
 (2, 16)" fillcolor=orange]
	140044872744336 -> 140052779891424 [dir=none]
	140052779891424 [label="weight
 (256)" fillcolor=orange]
	140044872744336 [label="NativeGroupNormBackward0
------------------------
C      :            256
HxW    :             25
N      :              2
eps    :          1e-05
group  :             16
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872744816 -> 140044872744336
	140044872744816 -> 140044873117760 [dir=none]
	140044873117760 [label="input
 (2, 128, 10, 10)" fillcolor=orange]
	140044872744816 -> 140052779889984 [dir=none]
	140052779889984 [label="weight
 (256, 128, 1, 1)" fillcolor=orange]
	140044872744816 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872839424 -> 140044872744816
	140044872839472 -> 140044872744816
	140052779889984 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140052779889984 -> 140044872839472
	140044872839472 [label=AccumulateGrad]
	140044872744624 -> 140044872744336
	140052779891424 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	140052779891424 -> 140044872744624
	140044872744624 [label=AccumulateGrad]
	140044872744576 -> 140044872744336
	140052779891024 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	140052779891024 -> 140044872744576
	140044872744576 [label=AccumulateGrad]
	140044872744192 -> 140044872744000
	140052779891744 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140052779891744 -> 140044872744192
	140044872744192 [label=AccumulateGrad]
	140044872743952 -> 140044872743904
	140052779890224 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.1.bn1.weight
 (256)" fillcolor=lightblue]
	140052779890224 -> 140044872743952
	140044872743952 [label=AccumulateGrad]
	140044872743808 -> 140044872743904
	140052779889904 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.1.bn1.bias
 (256)" fillcolor=lightblue]
	140052779889904 -> 140044872743808
	140044872743808 [label=AccumulateGrad]
	140044872743712 -> 140044872743568
	140052779892304 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140052779892304 -> 140044872743712
	140044872743712 [label=AccumulateGrad]
	140044872743520 -> 140044872743424
	140052779891904 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.1.bn2.weight
 (256)" fillcolor=lightblue]
	140052779891904 -> 140044872743520
	140044872743520 [label=AccumulateGrad]
	140044872743472 -> 140044872743424
	140052779890384 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.6.1.bn2.bias
 (256)" fillcolor=lightblue]
	140052779890384 -> 140044872743472
	140044872743472 [label=AccumulateGrad]
	140044872743376 -> 140044872743328
	140044872743088 -> 140044872742944
	140052779983712 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	140052779983712 -> 140044872743088
	140044872743088 [label=AccumulateGrad]
	140044872742896 -> 140044872742848
	140052779892464 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.0.bn1.weight
 (512)" fillcolor=lightblue]
	140052779892464 -> 140044872742896
	140044872742896 [label=AccumulateGrad]
	140044872742752 -> 140044872742848
	140052779892064 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.0.bn1.bias
 (512)" fillcolor=lightblue]
	140052779892064 -> 140044872742752
	140044872742752 [label=AccumulateGrad]
	140044872742464 -> 140044872742512
	140052779984272 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140052779984272 -> 140044872742464
	140044872742464 [label=AccumulateGrad]
	140044872742032 -> 140044872742416
	140052779889744 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.0.bn2.weight
 (512)" fillcolor=lightblue]
	140052779889744 -> 140044872742032
	140044872742032 [label=AccumulateGrad]
	140044872742128 -> 140044872742416
	140052779888704 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.0.bn2.bias
 (512)" fillcolor=lightblue]
	140052779888704 -> 140044872742128
	140044872742128 [label=AccumulateGrad]
	140044872741600 -> 140044872741840
	140044872741600 -> 140044873118960 [dir=none]
	140044873118960 [label="input
 (2, 512, 3, 3)" fillcolor=orange]
	140044872741600 -> 140044872829104 [dir=none]
	140044872829104 [label="result1
 (2, 32)" fillcolor=orange]
	140044872741600 -> 140044872827344 [dir=none]
	140044872827344 [label="result2
 (2, 32)" fillcolor=orange]
	140044872741600 -> 140052779891984 [dir=none]
	140052779891984 [label="weight
 (512)" fillcolor=orange]
	140044872741600 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              9
N      :              2
eps    :          1e-05
group  :             32
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872743040 -> 140044872741600
	140044872743040 -> 140044873118480 [dir=none]
	140044873118480 [label="input
 (2, 256, 5, 5)" fillcolor=orange]
	140044872743040 -> 140052779982992 [dir=none]
	140052779982992 [label="weight
 (512, 256, 1, 1)" fillcolor=orange]
	140044872743040 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:           (0,)
dilation      :         (1, 1)
groups        :              1
input         : [saved tensor]
output_padding:         (0, 0)
padding       :         (0, 0)
stride        :         (2, 2)
transposed    :          False
weight        : [saved tensor]"]
	140044872743184 -> 140044872743040
	140044872743232 -> 140044872743040
	140052779982992 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140052779982992 -> 140044872743232
	140044872743232 [label=AccumulateGrad]
	140044872742608 -> 140044872741600
	140052779891984 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	140052779891984 -> 140044872742608
	140044872742608 [label=AccumulateGrad]
	140044872742656 -> 140044872741600
	140052779890944 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	140052779890944 -> 140044872742656
	140044872742656 [label=AccumulateGrad]
	140044872741408 -> 140044872707712
	140052785110528 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140052785110528 -> 140044872741408
	140044872741408 [label=AccumulateGrad]
	140044872707952 -> 140044872708000
	140052779891504 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.1.bn1.weight
 (512)" fillcolor=lightblue]
	140052779891504 -> 140044872707952
	140044872707952 [label=AccumulateGrad]
	140044872707088 -> 140044872708000
	140052779890304 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.1.bn1.bias
 (512)" fillcolor=lightblue]
	140052779890304 -> 140044872707088
	140044872707088 [label=AccumulateGrad]
	140044872707472 -> 140044872706848
	140052785108128 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140052785108128 -> 140044872707472
	140044872707472 [label=AccumulateGrad]
	140044872705552 -> 140044872705888
	140052785110688 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.1.bn2.weight
 (512)" fillcolor=lightblue]
	140052785110688 -> 140044872705552
	140044872705552 [label=AccumulateGrad]
	140044872705792 -> 140044872705888
	140052785110288 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.backbone.nets.7.1.bn2.bias
 (512)" fillcolor=lightblue]
	140052785110288 -> 140044872705792
	140044872705792 [label=AccumulateGrad]
	140044872704448 -> 140044872704928
	140044872683328 -> 140044872682800
	140052785110128 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.pool.nets.weight
 (32, 512, 1, 1)" fillcolor=lightblue]
	140052785110128 -> 140044872683328
	140044872683328 [label=AccumulateGrad]
	140044872680640 -> 140044872682800
	140052785109808 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.pool.nets.bias
 (32)" fillcolor=lightblue]
	140052785109808 -> 140044872680640
	140044872680640 [label=AccumulateGrad]
	140044872680976 -> 140044872680448
	140044872680976 [label="SumBackward1
-------------------
dim       :    (1,)
keepdim   :    True
self_sizes: (64, 9)"]
	140044872682608 -> 140044872680976
	140044872682608 -> 140052785109968 [dir=none]
	140052785109968 [label="self
 (1, 9)" fillcolor=orange]
	140044872682608 [label="MulBackward0
---------------------
other:           None
self : [saved tensor]"]
	140044872682560 -> 140044872682608
	140044872649648 -> 140044872650608
	140044872649648 [label=TBackward0]
	140044872680400 -> 140044872649648
	140052785107248 [label="obs_encoder.obs_nets.robot0_eye_in_hand_image.nets.3.weight
 (64, 64)" fillcolor=lightblue]
	140052785107248 -> 140044872680400
	140044872680400 [label=AccumulateGrad]
	140044872647872 -> 140044872648496
	140044872647872 [label=TBackward0]
	140044872649264 -> 140044872647872
	140052779231248 [label="model.up_modules.1.1.cond_encoder.1.weight
 (1024, 402)" fillcolor=lightblue]
	140052779231248 -> 140044872649264
	140044872649264 [label=AccumulateGrad]
	140044872647776 -> 140044872647680
	140044872647776 -> 140044873134544 [dir=none]
	140044873134544 [label="self
 (1, 512, 8)" fillcolor=orange]
	140044872647776 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872648160 -> 140044872647776
	140044872648160 -> 140044873134144 [dir=none]
	140044873134144 [label="input
 (1, 512, 8)" fillcolor=orange]
	140044872648160 -> 140044872828864 [dir=none]
	140044872828864 [label="result1
 (1, 8)" fillcolor=orange]
	140044872648160 -> 140044872388672 [dir=none]
	140044872388672 [label="result2
 (1, 8)" fillcolor=orange]
	140044872648160 -> 140052779230768 [dir=none]
	140052779230768 [label="weight
 (512)" fillcolor=orange]
	140044872648160 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              8
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872648352 -> 140044872648160
	140044872648352 -> 140044873134624 [dir=none]
	140044873134624 [label="input
 (1, 512, 8)" fillcolor=orange]
	140044872648352 -> 140052779230608 [dir=none]
	140052779230608 [label="weight
 (512, 512, 5)" fillcolor=orange]
	140044872648352 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (512,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872647008 -> 140044872648352
	140044872647008 [label="AddBackward0
------------
alpha: 1"]
	140044872649792 -> 140044872647008
	140044872649792 -> 140044873134464 [dir=none]
	140044873134464 [label="self
 (1, 512, 8)" fillcolor=orange]
	140044872649792 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872650512 -> 140044872649792
	140044872650512 -> 140044873134384 [dir=none]
	140044873134384 [label="input
 (1, 512, 8)" fillcolor=orange]
	140044872650512 -> 140044872388912 [dir=none]
	140044872388912 [label="result1
 (1, 8)" fillcolor=orange]
	140044872650512 -> 140044872388832 [dir=none]
	140044872388832 [label="result2
 (1, 8)" fillcolor=orange]
	140044872650512 -> 140052779230128 [dir=none]
	140052779230128 [label="weight
 (512)" fillcolor=orange]
	140044872650512 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              8
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872679920 -> 140044872650512
	140044872679920 -> 140044873134304 [dir=none]
	140044873134304 [label="input
 (1, 512, 8)" fillcolor=orange]
	140044872679920 -> 140052779229968 [dir=none]
	140052779229968 [label="weight
 (512, 512, 5)" fillcolor=orange]
	140044872679920 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (512,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872681936 -> 140044872679920
	140044872681936 [label="AddBackward0
------------
alpha: 1"]
	140044872705840 -> 140044872681936
	140044872705840 -> 140044873133728 [dir=none]
	140044873133728 [label="other
 (1, 512, 8)" fillcolor=orange]
	140044872705840 -> 140044873133968 [dir=none]
	140044873133968 [label="self
 (1, 512, 1)" fillcolor=orange]
	140044872705840 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140044872706608 -> 140044872705840
	140044872706608 [label="SelectBackward0
--------------------------
dim       :              1
index     :              0
self_sizes: (1, 2, 512, 1)"]
	140044872741024 -> 140044872706608
	140044872741024 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:      (1, 2, 512, 1)
start     :                   0
step      :                   1"]
	140044872743616 -> 140044872741024
	140044872743616 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 1024, 1)"]
	140044872743280 -> 140044872743616
	140044872743280 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 1024)"]
	140044872744144 -> 140044872743280
	140044872744144 [label="PermuteBackward0
----------------
dims: (0, 1)"]
	140044872743856 -> 140044872744144
	140044872743856 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 1024)"]
	140044872744240 -> 140044872743856
	140044872744240 -> 140044873133808 [dir=none]
	140044873133808 [label="mat1
 (1, 402)" fillcolor=orange]
	140044872744240 -> 140044872389392 [dir=none]
	140044872389392 [label="mat2
 (402, 1024)" fillcolor=orange]
	140044872744240 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 402)
mat1_strides:       (402, 1)
mat2        : [saved tensor]
mat2_sizes  :    (402, 1024)
mat2_strides:       (1, 402)"]
	140044872741360 -> 140044872744240
	140052779230368 [label="model.up_modules.1.0.cond_encoder.1.bias
 (1024)" fillcolor=lightblue]
	140052779230368 -> 140044872741360
	140044872741360 [label=AccumulateGrad]
	140044872839856 -> 140044872744240
	140044872839856 -> 140044873119600 [dir=none]
	140044873119600 [label="self
 (1, 402)" fillcolor=orange]
	140044872839856 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872648688 -> 140044872839856
	140044872839328 -> 140044872744240
	140044872839328 [label=TBackward0]
	140044872840384 -> 140044872839328
	140052779230288 [label="model.up_modules.1.0.cond_encoder.1.weight
 (1024, 402)" fillcolor=lightblue]
	140052779230288 -> 140044872840384
	140044872840384 [label=AccumulateGrad]
	140044872705984 -> 140044872705840
	140044872705984 -> 140044873133648 [dir=none]
	140044873133648 [label="self
 (1, 512, 8)" fillcolor=orange]
	140044872705984 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872743664 -> 140044872705984
	140044872743664 -> 140044873133568 [dir=none]
	140044873133568 [label="input
 (1, 512, 8)" fillcolor=orange]
	140044872743664 -> 140044872389232 [dir=none]
	140044872389232 [label="result1
 (1, 8)" fillcolor=orange]
	140044872743664 -> 140044872389472 [dir=none]
	140044872389472 [label="result2
 (1, 8)" fillcolor=orange]
	140044872743664 -> 140052779229808 [dir=none]
	140052779229808 [label="weight
 (512)" fillcolor=orange]
	140044872743664 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :              8
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872744048 -> 140044872743664
	140044872744048 -> 140044873132368 [dir=none]
	140044873132368 [label="input
 (1, 2048, 8)" fillcolor=orange]
	140044872744048 -> 140052779229648 [dir=none]
	140052779229648 [label="weight
 (512, 2048, 5)" fillcolor=orange]
	140044872744048 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (512,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872840096 -> 140044872744048
	140044872840096 [label="CatBackward0
------------
dim: 1"]
	140044872840336 -> 140044872840096
	140044872840336 -> 140044873133248 [dir=none]
	140044873133248 [label="input
 (1, 1024, 4)" fillcolor=orange]
	140044872840336 -> 140052880927296 [dir=none]
	140052880927296 [label="weight
 (1024, 1024, 4)" fillcolor=orange]
	140044872840336 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (1024,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (1,)
stride        :           (2,)
transposed    :           True
weight        : [saved tensor]"]
	140044872841872 -> 140044872840336
	140044872841872 [label="AddBackward0
------------
alpha: 1"]
	140044872842256 -> 140044872841872
	140044872842256 -> 140044873133488 [dir=none]
	140044873133488 [label="self
 (1, 1024, 4)" fillcolor=orange]
	140044872842256 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872842304 -> 140044872842256
	140044872842304 -> 140044873133408 [dir=none]
	140044873133408 [label="input
 (1, 1024, 4)" fillcolor=orange]
	140044872842304 -> 140044872388752 [dir=none]
	140044872388752 [label="result1
 (1, 8)" fillcolor=orange]
	140044872842304 -> 140044872388992 [dir=none]
	140044872388992 [label="result2
 (1, 8)" fillcolor=orange]
	140044872842304 -> 140052779229248 [dir=none]
	140052779229248 [label="weight
 (1024)" fillcolor=orange]
	140044872842304 [label="NativeGroupNormBackward0
------------------------
C      :           1024
HxW    :              4
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872842832 -> 140044872842304
	140044872842832 -> 140044873133328 [dir=none]
	140044873133328 [label="input
 (1, 1024, 4)" fillcolor=orange]
	140044872842832 -> 140052779470656 [dir=none]
	140052779470656 [label="weight
 (1024, 1024, 5)" fillcolor=orange]
	140044872842832 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (1024,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872843024 -> 140044872842832
	140044872843024 [label="AddBackward0
------------
alpha: 1"]
	140044872872672 -> 140044872843024
	140044872872672 -> 140044873132448 [dir=none]
	140044873132448 [label="other
 (1, 1024, 4)" fillcolor=orange]
	140044872872672 -> 140044873133088 [dir=none]
	140044873133088 [label="self
 (1, 1024, 1)" fillcolor=orange]
	140044872872672 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140044872872720 -> 140044872872672
	140044872872720 [label="SelectBackward0
---------------------------
dim       :               1
index     :               0
self_sizes: (1, 2, 1024, 1)"]
	140044872872864 -> 140044872872720
	140044872872864 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 1024, 1)
start     :                   0
step      :                   1"]
	140044872872960 -> 140044872872864
	140044872872960 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 2048, 1)"]
	140044872873056 -> 140044872872960
	140044872873056 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 2048)"]
	140044872873152 -> 140044872873056
	140044872873152 [label="PermuteBackward0
----------------
dims: (0, 1)"]
	140044872873248 -> 140044872873152
	140044872873248 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 2048)"]
	140044872873344 -> 140044872873248
	140044872873344 -> 140044873132928 [dir=none]
	140044873132928 [label="mat1
 (1, 402)" fillcolor=orange]
	140044872873344 -> 140044872389872 [dir=none]
	140044872389872 [label="mat2
 (402, 2048)" fillcolor=orange]
	140044872873344 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 402)
mat1_strides:       (402, 1)
mat2        : [saved tensor]
mat2_sizes  :    (402, 2048)
mat2_strides:       (1, 402)"]
	140044872873440 -> 140044872873344
	140052779229488 [label="model.up_modules.0.1.cond_encoder.1.bias
 (2048)" fillcolor=lightblue]
	140052779229488 -> 140044872873440
	140044872873440 [label=AccumulateGrad]
	140044872873392 -> 140044872873344
	140044872873392 -> 140044873119600 [dir=none]
	140044873119600 [label="self
 (1, 402)" fillcolor=orange]
	140044872873392 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872648688 -> 140044872873392
	140044872872768 -> 140044872873344
	140044872872768 [label=TBackward0]
	140044872873632 -> 140044872872768
	140052779229408 [label="model.up_modules.0.1.cond_encoder.1.weight
 (2048, 402)" fillcolor=lightblue]
	140052779229408 -> 140044872873632
	140044872873632 [label=AccumulateGrad]
	140044872872480 -> 140044872872672
	140044872872480 -> 140044873132768 [dir=none]
	140044873132768 [label="self
 (1, 1024, 4)" fillcolor=orange]
	140044872872480 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872873008 -> 140044872872480
	140044872873008 -> 140044873131648 [dir=none]
	140044873131648 [label="input
 (1, 1024, 4)" fillcolor=orange]
	140044872873008 -> 140044872389632 [dir=none]
	140044872389632 [label="result1
 (1, 8)" fillcolor=orange]
	140044872873008 -> 140044872389952 [dir=none]
	140044872389952 [label="result2
 (1, 8)" fillcolor=orange]
	140044872873008 -> 140052779470496 [dir=none]
	140052779470496 [label="weight
 (1024)" fillcolor=orange]
	140044872873008 [label="NativeGroupNormBackward0
------------------------
C      :           1024
HxW    :              4
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872873200 -> 140044872873008
	140044872873200 -> 140044873132848 [dir=none]
	140044873132848 [label="input
 (1, 1024, 4)" fillcolor=orange]
	140044872873200 -> 140052779470336 [dir=none]
	140052779470336 [label="weight
 (1024, 1024, 5)" fillcolor=orange]
	140044872873200 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (1024,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872842352 -> 140044872873200
	140044872842352 [label="AddBackward0
------------
alpha: 1"]
	140044872873776 -> 140044872842352
	140044872873776 -> 140044873132688 [dir=none]
	140044873132688 [label="self
 (1, 1024, 4)" fillcolor=orange]
	140044872873776 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872873920 -> 140044872873776
	140044872873920 -> 140044873132608 [dir=none]
	140044873132608 [label="input
 (1, 1024, 4)" fillcolor=orange]
	140044872873920 -> 140044872389552 [dir=none]
	140044872389552 [label="result1
 (1, 8)" fillcolor=orange]
	140044872873920 -> 140044872389792 [dir=none]
	140044872389792 [label="result2
 (1, 8)" fillcolor=orange]
	140044872873920 -> 140052779469856 [dir=none]
	140052779469856 [label="weight
 (1024)" fillcolor=orange]
	140044872873920 [label="NativeGroupNormBackward0
------------------------
C      :           1024
HxW    :              4
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872874016 -> 140044872873920
	140044872874016 -> 140044873132528 [dir=none]
	140044873132528 [label="input
 (1, 1024, 4)" fillcolor=orange]
	140044872874016 -> 140052779469696 [dir=none]
	140052779469696 [label="weight
 (1024, 1024, 5)" fillcolor=orange]
	140044872874016 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (1024,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872874208 -> 140044872874016
	140044872874208 [label="AddBackward0
------------
alpha: 1"]
	140044872874400 -> 140044872874208
	140044872874400 -> 140044873132048 [dir=none]
	140044873132048 [label="other
 (1, 1024, 4)" fillcolor=orange]
	140044872874400 -> 140044873132288 [dir=none]
	140044873132288 [label="self
 (1, 1024, 1)" fillcolor=orange]
	140044872874400 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140044872874544 -> 140044872874400
	140044872874544 [label="SelectBackward0
---------------------------
dim       :               1
index     :               0
self_sizes: (1, 2, 1024, 1)"]
	140044872874688 -> 140044872874544
	140044872874688 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 1024, 1)
start     :                   0
step      :                   1"]
	140044872874784 -> 140044872874688
	140044872874784 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 2048, 1)"]
	140044872874880 -> 140044872874784
	140044872874880 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 2048)"]
	140044872874976 -> 140044872874880
	140044872874976 [label="PermuteBackward0
----------------
dims: (0, 1)"]
	140044872875072 -> 140044872874976
	140044872875072 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 2048)"]
	140044872875168 -> 140044872875072
	140044872875168 -> 140044873132128 [dir=none]
	140044873132128 [label="mat1
 (1, 402)" fillcolor=orange]
	140044872875168 -> 140044872389312 [dir=none]
	140044872389312 [label="mat2
 (402, 2048)" fillcolor=orange]
	140044872875168 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 402)
mat1_strides:       (402, 1)
mat2        : [saved tensor]
mat2_sizes  :    (402, 2048)
mat2_strides:       (1, 402)"]
	140044872875264 -> 140044872875168
	140052779470096 [label="model.up_modules.0.0.cond_encoder.1.bias
 (2048)" fillcolor=lightblue]
	140052779470096 -> 140044872875264
	140044872875264 [label=AccumulateGrad]
	140044872875216 -> 140044872875168
	140044872875216 -> 140044873119600 [dir=none]
	140044873119600 [label="self
 (1, 402)" fillcolor=orange]
	140044872875216 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872648688 -> 140044872875216
	140044872874592 -> 140044872875168
	140044872874592 [label=TBackward0]
	140044872875456 -> 140044872874592
	140052779470016 [label="model.up_modules.0.0.cond_encoder.1.weight
 (2048, 402)" fillcolor=lightblue]
	140052779470016 -> 140044872875456
	140044872875456 [label=AccumulateGrad]
	140044872874496 -> 140044872874400
	140044872874496 -> 140044873131968 [dir=none]
	140044873131968 [label="self
 (1, 1024, 4)" fillcolor=orange]
	140044872874496 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872874832 -> 140044872874496
	140044872874832 -> 140044873131568 [dir=none]
	140044873131568 [label="input
 (1, 1024, 4)" fillcolor=orange]
	140044872874832 -> 140044872389072 [dir=none]
	140044872389072 [label="result1
 (1, 8)" fillcolor=orange]
	140044872874832 -> 140044872390272 [dir=none]
	140044872390272 [label="result2
 (1, 8)" fillcolor=orange]
	140044872874832 -> 140052779469536 [dir=none]
	140052779469536 [label="weight
 (1024)" fillcolor=orange]
	140044872874832 [label="NativeGroupNormBackward0
------------------------
C      :           1024
HxW    :              4
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872875024 -> 140044872874832
	140044872875024 -> 140044873129872 [dir=none]
	140044873129872 [label="input
 (1, 4096, 4)" fillcolor=orange]
	140044872875024 -> 140052779469376 [dir=none]
	140052779469376 [label="weight
 (1024, 4096, 5)" fillcolor=orange]
	140044872875024 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (1024,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872875552 -> 140044872875024
	140044872875552 [label="CatBackward0
------------
dim: 1"]
	140044872875648 -> 140044872875552
	140044872875648 [label="AddBackward0
------------
alpha: 1"]
	140044872875792 -> 140044872875648
	140044872875792 -> 140044873131888 [dir=none]
	140044873131888 [label="self
 (1, 2048, 4)" fillcolor=orange]
	140044872875792 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872875936 -> 140044872875792
	140044872875936 -> 140044873131808 [dir=none]
	140044873131808 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872875936 -> 140044872390112 [dir=none]
	140044872390112 [label="result1
 (1, 8)" fillcolor=orange]
	140044872875936 -> 140044872390032 [dir=none]
	140044872390032 [label="result2
 (1, 8)" fillcolor=orange]
	140044872875936 -> 140052785088848 [dir=none]
	140052785088848 [label="weight
 (2048)" fillcolor=orange]
	140044872875936 [label="NativeGroupNormBackward0
------------------------
C      :           2048
HxW    :              4
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872875984 -> 140044872875936
	140044872875984 -> 140044873131728 [dir=none]
	140044873131728 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872875984 -> 140052785089808 [dir=none]
	140052785089808 [label="weight
 (2048, 2048, 5)" fillcolor=orange]
	140044872875984 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (2048,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872421632 -> 140044872875984
	140044872421632 [label="AddBackward0
------------
alpha: 1"]
	140044872421824 -> 140044872421632
	140044872421824 -> 140044873131248 [dir=none]
	140044873131248 [label="other
 (1, 2048, 4)" fillcolor=orange]
	140044872421824 -> 140044873131488 [dir=none]
	140044873131488 [label="self
 (1, 2048, 1)" fillcolor=orange]
	140044872421824 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140044872421968 -> 140044872421824
	140044872421968 [label="SelectBackward0
---------------------------
dim       :               1
index     :               0
self_sizes: (1, 2, 2048, 1)"]
	140044872422112 -> 140044872421968
	140044872422112 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 2048, 1)
start     :                   0
step      :                   1"]
	140044872422208 -> 140044872422112
	140044872422208 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 4096, 1)"]
	140044872422304 -> 140044872422208
	140044872422304 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 4096)"]
	140044872422400 -> 140044872422304
	140044872422400 [label="PermuteBackward0
----------------
dims: (0, 1)"]
	140044872422496 -> 140044872422400
	140044872422496 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 4096)"]
	140044872422592 -> 140044872422496
	140044872422592 -> 140044873131328 [dir=none]
	140044873131328 [label="mat1
 (1, 402)" fillcolor=orange]
	140044872422592 -> 140044872389152 [dir=none]
	140044872389152 [label="mat2
 (402, 4096)" fillcolor=orange]
	140044872422592 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 402)
mat1_strides:       (402, 1)
mat2        : [saved tensor]
mat2_sizes  :    (402, 4096)
mat2_strides:       (1, 402)"]
	140044872422688 -> 140044872422592
	140052779984672 [label="model.mid_modules.1.cond_encoder.1.bias
 (4096)" fillcolor=lightblue]
	140052779984672 -> 140044872422688
	140044872422688 [label=AccumulateGrad]
	140044872422640 -> 140044872422592
	140044872422640 -> 140044873119600 [dir=none]
	140044873119600 [label="self
 (1, 402)" fillcolor=orange]
	140044872422640 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872648688 -> 140044872422640
	140044872422016 -> 140044872422592
	140044872422016 [label=TBackward0]
	140044872422880 -> 140044872422016
	140052785088928 [label="model.mid_modules.1.cond_encoder.1.weight
 (4096, 402)" fillcolor=lightblue]
	140052785088928 -> 140044872422880
	140044872422880 [label=AccumulateGrad]
	140044872421920 -> 140044872421824
	140044872421920 -> 140044873131168 [dir=none]
	140044873131168 [label="self
 (1, 2048, 4)" fillcolor=orange]
	140044872421920 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872422256 -> 140044872421920
	140044872422256 -> 140044873130768 [dir=none]
	140044873130768 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872422256 -> 140044872390192 [dir=none]
	140044872390192 [label="result1
 (1, 8)" fillcolor=orange]
	140044872422256 -> 140044872390672 [dir=none]
	140044872390672 [label="result2
 (1, 8)" fillcolor=orange]
	140044872422256 -> 140052785089568 [dir=none]
	140052785089568 [label="weight
 (2048)" fillcolor=orange]
	140044872422256 [label="NativeGroupNormBackward0
------------------------
C      :           2048
HxW    :              4
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872422448 -> 140044872422256
	140044872422448 -> 140044873130848 [dir=none]
	140044873130848 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872422448 -> 140052785087568 [dir=none]
	140052785087568 [label="weight
 (2048, 2048, 5)" fillcolor=orange]
	140044872422448 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (2048,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872875744 -> 140044872422448
	140044872875744 [label="AddBackward0
------------
alpha: 1"]
	140044872423024 -> 140044872875744
	140044872423024 -> 140044873131088 [dir=none]
	140044873131088 [label="self
 (1, 2048, 4)" fillcolor=orange]
	140044872423024 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872423120 -> 140044872423024
	140044872423120 -> 140044873131008 [dir=none]
	140044873131008 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872423120 -> 140044872390512 [dir=none]
	140044872390512 [label="result1
 (1, 8)" fillcolor=orange]
	140044872423120 -> 140044872390352 [dir=none]
	140044872390352 [label="result2
 (1, 8)" fillcolor=orange]
	140044872423120 -> 140052785090368 [dir=none]
	140052785090368 [label="weight
 (2048)" fillcolor=orange]
	140044872423120 [label="NativeGroupNormBackward0
------------------------
C      :           2048
HxW    :              4
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872423216 -> 140044872423120
	140044872423216 -> 140044873130928 [dir=none]
	140044873130928 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872423216 -> 140052785088608 [dir=none]
	140052785088608 [label="weight
 (2048, 2048, 5)" fillcolor=orange]
	140044872423216 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (2048,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872423408 -> 140044872423216
	140044872423408 [label="AddBackward0
------------
alpha: 1"]
	140044872423600 -> 140044872423408
	140044872423600 -> 140044873130448 [dir=none]
	140044873130448 [label="other
 (1, 2048, 4)" fillcolor=orange]
	140044872423600 -> 140044873130688 [dir=none]
	140044873130688 [label="self
 (1, 2048, 1)" fillcolor=orange]
	140044872423600 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140044872423744 -> 140044872423600
	140044872423744 [label="SelectBackward0
---------------------------
dim       :               1
index     :               0
self_sizes: (1, 2, 2048, 1)"]
	140044872423888 -> 140044872423744
	140044872423888 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 2048, 1)
start     :                   0
step      :                   1"]
	140044872423984 -> 140044872423888
	140044872423984 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 4096, 1)"]
	140044872424080 -> 140044872423984
	140044872424080 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 4096)"]
	140044872424176 -> 140044872424080
	140044872424176 [label="PermuteBackward0
----------------
dims: (0, 1)"]
	140044872424272 -> 140044872424176
	140044872424272 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 4096)"]
	140044872424368 -> 140044872424272
	140044872424368 -> 140044873130528 [dir=none]
	140044873130528 [label="mat1
 (1, 402)" fillcolor=orange]
	140044872424368 -> 140044872390432 [dir=none]
	140044872390432 [label="mat2
 (402, 4096)" fillcolor=orange]
	140044872424368 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 402)
mat1_strides:       (402, 1)
mat2        : [saved tensor]
mat2_sizes  :    (402, 4096)
mat2_strides:       (1, 402)"]
	140044872424464 -> 140044872424368
	140052785089248 [label="model.mid_modules.0.cond_encoder.1.bias
 (4096)" fillcolor=lightblue]
	140052785089248 -> 140044872424464
	140044872424464 [label=AccumulateGrad]
	140044872424416 -> 140044872424368
	140044872424416 -> 140044873119600 [dir=none]
	140044873119600 [label="self
 (1, 402)" fillcolor=orange]
	140044872424416 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872648688 -> 140044872424416
	140044872423792 -> 140044872424368
	140044872423792 [label=TBackward0]
	140044872424656 -> 140044872423792
	140052792470320 [label="model.mid_modules.0.cond_encoder.1.weight
 (4096, 402)" fillcolor=lightblue]
	140052792470320 -> 140044872424656
	140044872424656 [label=AccumulateGrad]
	140044872423696 -> 140044872423600
	140044872423696 -> 140044873130368 [dir=none]
	140044873130368 [label="self
 (1, 2048, 4)" fillcolor=orange]
	140044872423696 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872424032 -> 140044872423696
	140044872424032 -> 140044873126832 [dir=none]
	140044873126832 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872424032 -> 140044872390592 [dir=none]
	140044872390592 [label="result1
 (1, 8)" fillcolor=orange]
	140044872424032 -> 140044872391072 [dir=none]
	140044872391072 [label="result2
 (1, 8)" fillcolor=orange]
	140044872424032 -> 140052785088768 [dir=none]
	140052785088768 [label="weight
 (2048)" fillcolor=orange]
	140044872424032 [label="NativeGroupNormBackward0
------------------------
C      :           2048
HxW    :              4
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872424224 -> 140044872424032
	140044872424224 -> 140044873130048 [dir=none]
	140044873130048 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872424224 -> 140052880928016 [dir=none]
	140052880928016 [label="weight
 (2048, 2048, 5)" fillcolor=orange]
	140044872424224 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (2048,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872875600 -> 140044872424224
	140044872875600 [label="AddBackward0
------------
alpha: 1"]
	140044872424800 -> 140044872875600
	140044872424800 -> 140044873130288 [dir=none]
	140044873130288 [label="self
 (1, 2048, 4)" fillcolor=orange]
	140044872424800 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872424944 -> 140044872424800
	140044872424944 -> 140044873130208 [dir=none]
	140044873130208 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872424944 -> 140044872390912 [dir=none]
	140044872390912 [label="result1
 (1, 8)" fillcolor=orange]
	140044872424944 -> 140044872390752 [dir=none]
	140044872390752 [label="result2
 (1, 8)" fillcolor=orange]
	140044872424944 -> 140052779469056 [dir=none]
	140052779469056 [label="weight
 (2048)" fillcolor=orange]
	140044872424944 [label="NativeGroupNormBackward0
------------------------
C      :           2048
HxW    :              4
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872425040 -> 140044872424944
	140044872425040 -> 140044873130128 [dir=none]
	140044873130128 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872425040 -> 140052779468896 [dir=none]
	140052779468896 [label="weight
 (2048, 2048, 5)" fillcolor=orange]
	140044872425040 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (2048,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872425232 -> 140044872425040
	140044872425232 [label="AddBackward0
------------
alpha: 1"]
	140044872425424 -> 140044872425232
	140044872425424 -> 140044873129152 [dir=none]
	140044873129152 [label="other
 (1, 2048, 4)" fillcolor=orange]
	140044872425424 -> 140044873129792 [dir=none]
	140044873129792 [label="self
 (1, 2048, 1)" fillcolor=orange]
	140044872425424 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140044872462496 -> 140044872425424
	140044872462496 [label="SelectBackward0
---------------------------
dim       :               1
index     :               0
self_sizes: (1, 2, 2048, 1)"]
	140044872462640 -> 140044872462496
	140044872462640 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 2048, 1)
start     :                   0
step      :                   1"]
	140044872462736 -> 140044872462640
	140044872462736 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 4096, 1)"]
	140044872462832 -> 140044872462736
	140044872462832 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 4096)"]
	140044872462928 -> 140044872462832
	140044872462928 [label="PermuteBackward0
----------------
dims: (0, 1)"]
	140044872463024 -> 140044872462928
	140044872463024 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 4096)"]
	140044872463120 -> 140044872463024
	140044872463120 -> 140044873129632 [dir=none]
	140044873129632 [label="mat1
 (1, 402)" fillcolor=orange]
	140044872463120 -> 140044872390832 [dir=none]
	140044872390832 [label="mat2
 (402, 4096)" fillcolor=orange]
	140044872463120 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 402)
mat1_strides:       (402, 1)
mat2        : [saved tensor]
mat2_sizes  :    (402, 4096)
mat2_strides:       (1, 402)"]
	140044872463216 -> 140044872463120
	140052779469296 [label="model.down_modules.2.1.cond_encoder.1.bias
 (4096)" fillcolor=lightblue]
	140052779469296 -> 140044872463216
	140044872463216 [label=AccumulateGrad]
	140044872463168 -> 140044872463120
	140044872463168 -> 140044873119600 [dir=none]
	140044873119600 [label="self
 (1, 402)" fillcolor=orange]
	140044872463168 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872648688 -> 140044872463168
	140044872462544 -> 140044872463120
	140044872462544 [label=TBackward0]
	140044872463408 -> 140044872462544
	140052779469216 [label="model.down_modules.2.1.cond_encoder.1.weight
 (4096, 402)" fillcolor=lightblue]
	140052779469216 -> 140044872463408
	140044872463408 [label=AccumulateGrad]
	140044872462448 -> 140044872425424
	140044872462448 -> 140044873129472 [dir=none]
	140044873129472 [label="self
 (1, 2048, 4)" fillcolor=orange]
	140044872462448 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872462784 -> 140044872462448
	140044872462784 -> 140044873127552 [dir=none]
	140044873127552 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872462784 -> 140044872390992 [dir=none]
	140044872390992 [label="result1
 (1, 8)" fillcolor=orange]
	140044872462784 -> 140044872391472 [dir=none]
	140044872391472 [label="result2
 (1, 8)" fillcolor=orange]
	140044872462784 -> 140052779468736 [dir=none]
	140052779468736 [label="weight
 (2048)" fillcolor=orange]
	140044872462784 [label="NativeGroupNormBackward0
------------------------
C      :           2048
HxW    :              4
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872462976 -> 140044872462784
	140044872462976 -> 140044873129552 [dir=none]
	140044873129552 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872462976 -> 140052779468576 [dir=none]
	140052779468576 [label="weight
 (2048, 2048, 5)" fillcolor=orange]
	140044872462976 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (2048,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872424560 -> 140044872462976
	140044872424560 [label="AddBackward0
------------
alpha: 1"]
	140044872463552 -> 140044872424560
	140044872463552 -> 140044873129392 [dir=none]
	140044873129392 [label="self
 (1, 2048, 4)" fillcolor=orange]
	140044872463552 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872463696 -> 140044872463552
	140044872463696 -> 140044873129312 [dir=none]
	140044873129312 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872463696 -> 140044872391312 [dir=none]
	140044872391312 [label="result1
 (1, 8)" fillcolor=orange]
	140044872463696 -> 140044872391152 [dir=none]
	140044872391152 [label="result2
 (1, 8)" fillcolor=orange]
	140044872463696 -> 140052779468096 [dir=none]
	140052779468096 [label="weight
 (2048)" fillcolor=orange]
	140044872463696 [label="NativeGroupNormBackward0
------------------------
C      :           2048
HxW    :              4
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872463792 -> 140044872463696
	140044872463792 -> 140044873129232 [dir=none]
	140044873129232 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872463792 -> 140052779467936 [dir=none]
	140052779467936 [label="weight
 (2048, 2048, 5)" fillcolor=orange]
	140044872463792 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (2048,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872463984 -> 140044872463792
	140044872463984 [label="AddBackward0
------------
alpha: 1"]
	140044872464176 -> 140044872463984
	140044872464176 -> 140044873127872 [dir=none]
	140044873127872 [label="other
 (1, 2048, 4)" fillcolor=orange]
	140044872464176 -> 140044873126352 [dir=none]
	140044873126352 [label="self
 (1, 2048, 1)" fillcolor=orange]
	140044872464176 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140044872464320 -> 140044872464176
	140044872464320 [label="SelectBackward0
---------------------------
dim       :               1
index     :               0
self_sizes: (1, 2, 2048, 1)"]
	140044872464464 -> 140044872464320
	140044872464464 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 2048, 1)
start     :                   0
step      :                   1"]
	140044872464560 -> 140044872464464
	140044872464560 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 4096, 1)"]
	140044872464656 -> 140044872464560
	140044872464656 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 4096)"]
	140044872464752 -> 140044872464656
	140044872464752 [label="PermuteBackward0
----------------
dims: (0, 1)"]
	140044872464848 -> 140044872464752
	140044872464848 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 4096)"]
	140044872464944 -> 140044872464848
	140044872464944 -> 140044873127312 [dir=none]
	140044873127312 [label="mat1
 (1, 402)" fillcolor=orange]
	140044872464944 -> 140044872391232 [dir=none]
	140044872391232 [label="mat2
 (402, 4096)" fillcolor=orange]
	140044872464944 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 402)
mat1_strides:       (402, 1)
mat2        : [saved tensor]
mat2_sizes  :    (402, 4096)
mat2_strides:       (1, 402)"]
	140044872465040 -> 140044872464944
	140052779468336 [label="model.down_modules.2.0.cond_encoder.1.bias
 (4096)" fillcolor=lightblue]
	140052779468336 -> 140044872465040
	140044872465040 [label=AccumulateGrad]
	140044872464992 -> 140044872464944
	140044872464992 -> 140044873119600 [dir=none]
	140044873119600 [label="self
 (1, 402)" fillcolor=orange]
	140044872464992 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872648688 -> 140044872464992
	140044872464368 -> 140044872464944
	140044872464368 [label=TBackward0]
	140044872465232 -> 140044872464368
	140052779468256 [label="model.down_modules.2.0.cond_encoder.1.weight
 (4096, 402)" fillcolor=lightblue]
	140052779468256 -> 140044872465232
	140044872465232 [label=AccumulateGrad]
	140044872464272 -> 140044872464176
	140044872464272 -> 140044873128432 [dir=none]
	140044873128432 [label="self
 (1, 2048, 4)" fillcolor=orange]
	140044872464272 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872464608 -> 140044872464272
	140044872464608 -> 140044873128512 [dir=none]
	140044873128512 [label="input
 (1, 2048, 4)" fillcolor=orange]
	140044872464608 -> 140044872391392 [dir=none]
	140044872391392 [label="result1
 (1, 8)" fillcolor=orange]
	140044872464608 -> 140044872391872 [dir=none]
	140044872391872 [label="result2
 (1, 8)" fillcolor=orange]
	140044872464608 -> 140052779467776 [dir=none]
	140052779467776 [label="weight
 (2048)" fillcolor=orange]
	140044872464608 [label="NativeGroupNormBackward0
------------------------
C      :           2048
HxW    :              4
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872464800 -> 140044872464608
	140044872464800 -> 140044873127232 [dir=none]
	140044873127232 [label="input
 (1, 1024, 4)" fillcolor=orange]
	140044872464800 -> 140052779467616 [dir=none]
	140052779467616 [label="weight
 (2048, 1024, 5)" fillcolor=orange]
	140044872464800 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (2048,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872465328 -> 140044872464800
	140044872465328 -> 140044873128032 [dir=none]
	140044873128032 [label="input
 (1, 1024, 8)" fillcolor=orange]
	140044872465328 -> 140052779467456 [dir=none]
	140052779467456 [label="weight
 (1024, 1024, 3)" fillcolor=orange]
	140044872465328 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (1024,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (1,)
stride        :           (2,)
transposed    :          False
weight        : [saved tensor]"]
	140044872841248 -> 140044872465328
	140044872841248 [label="AddBackward0
------------
alpha: 1"]
	140044872465568 -> 140044872841248
	140044872465568 -> 140044873127952 [dir=none]
	140044873127952 [label="self
 (1, 1024, 8)" fillcolor=orange]
	140044872465568 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872465712 -> 140044872465568
	140044872465712 -> 140044873127712 [dir=none]
	140044873127712 [label="input
 (1, 1024, 8)" fillcolor=orange]
	140044872465712 -> 140044872391552 [dir=none]
	140044872391552 [label="result1
 (1, 8)" fillcolor=orange]
	140044872465712 -> 140044872391712 [dir=none]
	140044872391712 [label="result2
 (1, 8)" fillcolor=orange]
	140044872465712 -> 140052779467136 [dir=none]
	140052779467136 [label="weight
 (1024)" fillcolor=orange]
	140044872465712 [label="NativeGroupNormBackward0
------------------------
C      :           1024
HxW    :              8
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872465808 -> 140044872465712
	140044872465808 -> 140044873120480 [dir=none]
	140044873120480 [label="input
 (1, 1024, 8)" fillcolor=orange]
	140044872465808 -> 140052779466976 [dir=none]
	140052779466976 [label="weight
 (1024, 1024, 5)" fillcolor=orange]
	140044872465808 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (1024,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872466000 -> 140044872465808
	140044872466000 [label="AddBackward0
------------
alpha: 1"]
	140044872466192 -> 140044872466000
	140044872466192 -> 140044873127072 [dir=none]
	140044873127072 [label="other
 (1, 1024, 8)" fillcolor=orange]
	140044872466192 -> 140044873127472 [dir=none]
	140044873127472 [label="self
 (1, 1024, 1)" fillcolor=orange]
	140044872466192 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140044872466336 -> 140044872466192
	140044872466336 [label="SelectBackward0
---------------------------
dim       :               1
index     :               0
self_sizes: (1, 2, 1024, 1)"]
	140044872466384 -> 140044872466336
	140044872466384 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 1024, 1)
start     :                   0
step      :                   1"]
	140044872491216 -> 140044872466384
	140044872491216 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 2048, 1)"]
	140044872491312 -> 140044872491216
	140044872491312 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 2048)"]
	140044872491408 -> 140044872491312
	140044872491408 [label="PermuteBackward0
----------------
dims: (0, 1)"]
	140044872491504 -> 140044872491408
	140044872491504 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 2048)"]
	140044872491600 -> 140044872491504
	140044872491600 -> 140044873127152 [dir=none]
	140044873127152 [label="mat1
 (1, 402)" fillcolor=orange]
	140044872491600 -> 140044872392272 [dir=none]
	140044872392272 [label="mat2
 (402, 2048)" fillcolor=orange]
	140044872491600 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 402)
mat1_strides:       (402, 1)
mat2        : [saved tensor]
mat2_sizes  :    (402, 2048)
mat2_strides:       (1, 402)"]
	140044872491696 -> 140044872491600
	140052779467376 [label="model.down_modules.1.1.cond_encoder.1.bias
 (2048)" fillcolor=lightblue]
	140052779467376 -> 140044872491696
	140044872491696 [label=AccumulateGrad]
	140044872491648 -> 140044872491600
	140044872491648 -> 140044873119600 [dir=none]
	140044873119600 [label="self
 (1, 402)" fillcolor=orange]
	140044872491648 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872648688 -> 140044872491648
	140044872491120 -> 140044872491600
	140044872491120 [label=TBackward0]
	140044872491888 -> 140044872491120
	140052779467296 [label="model.down_modules.1.1.cond_encoder.1.weight
 (2048, 402)" fillcolor=lightblue]
	140052779467296 -> 140044872491888
	140044872491888 [label=AccumulateGrad]
	140044872466288 -> 140044872466192
	140044872466288 -> 140044873126912 [dir=none]
	140044873126912 [label="self
 (1, 1024, 8)" fillcolor=orange]
	140044872466288 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872491264 -> 140044872466288
	140044872491264 -> 140044873126432 [dir=none]
	140044873126432 [label="input
 (1, 1024, 8)" fillcolor=orange]
	140044872491264 -> 140044872392032 [dir=none]
	140044872392032 [label="result1
 (1, 8)" fillcolor=orange]
	140044872491264 -> 140044872392352 [dir=none]
	140044872392352 [label="result2
 (1, 8)" fillcolor=orange]
	140044872491264 -> 140052779466816 [dir=none]
	140052779466816 [label="weight
 (1024)" fillcolor=orange]
	140044872491264 [label="NativeGroupNormBackward0
------------------------
C      :           1024
HxW    :              8
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872491456 -> 140044872491264
	140044872491456 -> 140044873126672 [dir=none]
	140044873126672 [label="input
 (1, 1024, 8)" fillcolor=orange]
	140044872491456 -> 140052779986752 [dir=none]
	140052779986752 [label="weight
 (1024, 1024, 5)" fillcolor=orange]
	140044872491456 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (1024,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872465520 -> 140044872491456
	140044872465520 [label="AddBackward0
------------
alpha: 1"]
	140044872492032 -> 140044872465520
	140044872492032 -> 140044873126752 [dir=none]
	140044873126752 [label="self
 (1, 1024, 8)" fillcolor=orange]
	140044872492032 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872492176 -> 140044872492032
	140044872492176 -> 140044873126592 [dir=none]
	140044873126592 [label="input
 (1, 1024, 8)" fillcolor=orange]
	140044872492176 -> 140044872391952 [dir=none]
	140044872391952 [label="result1
 (1, 8)" fillcolor=orange]
	140044872492176 -> 140044872392192 [dir=none]
	140044872392192 [label="result2
 (1, 8)" fillcolor=orange]
	140044872492176 -> 140052779986272 [dir=none]
	140052779986272 [label="weight
 (1024)" fillcolor=orange]
	140044872492176 [label="NativeGroupNormBackward0
------------------------
C      :           1024
HxW    :              8
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872492272 -> 140044872492176
	140044872492272 -> 140044873126512 [dir=none]
	140044873126512 [label="input
 (1, 1024, 8)" fillcolor=orange]
	140044872492272 -> 140052779986112 [dir=none]
	140052779986112 [label="weight
 (1024, 1024, 5)" fillcolor=orange]
	140044872492272 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (1024,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872492464 -> 140044872492272
	140044872492464 [label="AddBackward0
------------
alpha: 1"]
	140044872492656 -> 140044872492464
	140044872492656 -> 140044873126032 [dir=none]
	140044873126032 [label="other
 (1, 1024, 8)" fillcolor=orange]
	140044872492656 -> 140044873126272 [dir=none]
	140044873126272 [label="self
 (1, 1024, 1)" fillcolor=orange]
	140044872492656 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140044872492800 -> 140044872492656
	140044872492800 [label="SelectBackward0
---------------------------
dim       :               1
index     :               0
self_sizes: (1, 2, 1024, 1)"]
	140044872492944 -> 140044872492800
	140044872492944 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 1024, 1)
start     :                   0
step      :                   1"]
	140044872493040 -> 140044872492944
	140044872493040 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 2048, 1)"]
	140044872493136 -> 140044872493040
	140044872493136 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 2048)"]
	140044872493232 -> 140044872493136
	140044872493232 [label="PermuteBackward0
----------------
dims: (0, 1)"]
	140044872493328 -> 140044872493232
	140044872493328 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 2048)"]
	140044872493424 -> 140044872493328
	140044872493424 -> 140044873126112 [dir=none]
	140044873126112 [label="mat1
 (1, 402)" fillcolor=orange]
	140044872493424 -> 140044872391632 [dir=none]
	140044872391632 [label="mat2
 (402, 2048)" fillcolor=orange]
	140044872493424 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 402)
mat1_strides:       (402, 1)
mat2        : [saved tensor]
mat2_sizes  :    (402, 2048)
mat2_strides:       (1, 402)"]
	140044872493520 -> 140044872493424
	140052779986512 [label="model.down_modules.1.0.cond_encoder.1.bias
 (2048)" fillcolor=lightblue]
	140052779986512 -> 140044872493520
	140044872493520 [label=AccumulateGrad]
	140044872493472 -> 140044872493424
	140044872493472 -> 140044873119600 [dir=none]
	140044873119600 [label="self
 (1, 402)" fillcolor=orange]
	140044872493472 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872648688 -> 140044872493472
	140044872492848 -> 140044872493424
	140044872492848 [label=TBackward0]
	140044872493712 -> 140044872492848
	140052779986432 [label="model.down_modules.1.0.cond_encoder.1.weight
 (2048, 402)" fillcolor=lightblue]
	140052779986432 -> 140044872493712
	140044872493712 [label=AccumulateGrad]
	140044872492752 -> 140044872492656
	140044872492752 -> 140044873125952 [dir=none]
	140044873125952 [label="self
 (1, 1024, 8)" fillcolor=orange]
	140044872492752 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872493088 -> 140044872492752
	140044872493088 -> 140044873121680 [dir=none]
	140044873121680 [label="input
 (1, 1024, 8)" fillcolor=orange]
	140044872493088 -> 140044872391792 [dir=none]
	140044872391792 [label="result1
 (1, 8)" fillcolor=orange]
	140044872493088 -> 140044872392112 [dir=none]
	140044872392112 [label="result2
 (1, 8)" fillcolor=orange]
	140044872493088 -> 140052779985952 [dir=none]
	140052779985952 [label="weight
 (1024)" fillcolor=orange]
	140044872493088 [label="NativeGroupNormBackward0
------------------------
C      :           1024
HxW    :              8
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872493280 -> 140044872493088
	140044872493280 -> 140044873121280 [dir=none]
	140044873121280 [label="input
 (1, 512, 8)" fillcolor=orange]
	140044872493280 -> 140052779985792 [dir=none]
	140052779985792 [label="weight
 (1024, 512, 5)" fillcolor=orange]
	140044872493280 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (1024,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872493808 -> 140044872493280
	140044872493808 -> 140044873121360 [dir=none]
	140044873121360 [label="input
 (1, 512, 16)" fillcolor=orange]
	140044872493808 -> 140052779985632 [dir=none]
	140052779985632 [label="weight
 (512, 512, 3)" fillcolor=orange]
	140044872493808 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (512,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (1,)
stride        :           (2,)
transposed    :          False
weight        : [saved tensor]"]
	140044872493904 -> 140044872493808
	140044872493904 [label="AddBackward0
------------
alpha: 1"]
	140044872494096 -> 140044872493904
	140044872494096 -> 140044873121600 [dir=none]
	140044873121600 [label="self
 (1, 512, 16)" fillcolor=orange]
	140044872494096 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872494240 -> 140044872494096
	140044872494240 -> 140044873121520 [dir=none]
	140044873121520 [label="input
 (1, 512, 16)" fillcolor=orange]
	140044872494240 -> 140044872392432 [dir=none]
	140044872392432 [label="result1
 (1, 8)" fillcolor=orange]
	140044872494240 -> 140044872392512 [dir=none]
	140044872392512 [label="result2
 (1, 8)" fillcolor=orange]
	140044872494240 -> 140052779985312 [dir=none]
	140052779985312 [label="weight
 (512)" fillcolor=orange]
	140044872494240 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :             16
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872494336 -> 140044872494240
	140044872494336 -> 140044873121440 [dir=none]
	140044873121440 [label="input
 (1, 512, 16)" fillcolor=orange]
	140044872494336 -> 140052779985152 [dir=none]
	140052779985152 [label="weight
 (512, 512, 5)" fillcolor=orange]
	140044872494336 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (512,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872494528 -> 140044872494336
	140044872494528 [label="AddBackward0
------------
alpha: 1"]
	140044872494720 -> 140044872494528
	140044872494720 -> 140044873120560 [dir=none]
	140044873120560 [label="other
 (1, 512, 16)" fillcolor=orange]
	140044872494720 -> 140044873121200 [dir=none]
	140044873121200 [label="self
 (1, 512, 1)" fillcolor=orange]
	140044872494720 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140044872494864 -> 140044872494720
	140044872494864 [label="SelectBackward0
--------------------------
dim       :              1
index     :              0
self_sizes: (1, 2, 512, 1)"]
	140044872495008 -> 140044872494864
	140044872495008 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:      (1, 2, 512, 1)
start     :                   0
step      :                   1"]
	140044872495056 -> 140044872495008
	140044872495056 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 1024, 1)"]
	140044872519840 -> 140044872495056
	140044872519840 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 1024)"]
	140044872519936 -> 140044872519840
	140044872519936 [label="PermuteBackward0
----------------
dims: (0, 1)"]
	140044872520032 -> 140044872519936
	140044872520032 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 1024)"]
	140044872520128 -> 140044872520032
	140044872520128 -> 140044873121040 [dir=none]
	140044873121040 [label="mat1
 (1, 402)" fillcolor=orange]
	140044872520128 -> 140044872392592 [dir=none]
	140044872392592 [label="mat2
 (402, 1024)" fillcolor=orange]
	140044872520128 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 402)
mat1_strides:       (402, 1)
mat2        : [saved tensor]
mat2_sizes  :    (402, 1024)
mat2_strides:       (1, 402)"]
	140044872520224 -> 140044872520128
	140052779985552 [label="model.down_modules.0.1.cond_encoder.1.bias
 (1024)" fillcolor=lightblue]
	140052779985552 -> 140044872520224
	140044872520224 [label=AccumulateGrad]
	140044872520176 -> 140044872520128
	140044872520176 -> 140044873119600 [dir=none]
	140044873119600 [label="self
 (1, 402)" fillcolor=orange]
	140044872520176 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872648688 -> 140044872520176
	140044872519744 -> 140044872520128
	140044872519744 [label=TBackward0]
	140044872520416 -> 140044872519744
	140052779985472 [label="model.down_modules.0.1.cond_encoder.1.weight
 (1024, 402)" fillcolor=lightblue]
	140052779985472 -> 140044872520416
	140044872520416 [label=AccumulateGrad]
	140044872494816 -> 140044872494720
	140044872494816 -> 140044873120880 [dir=none]
	140044873120880 [label="self
 (1, 512, 16)" fillcolor=orange]
	140044872494816 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872494912 -> 140044872494816
	140044872494912 -> 140044873119920 [dir=none]
	140044873119920 [label="input
 (1, 512, 16)" fillcolor=orange]
	140044872494912 -> 140044872389712 [dir=none]
	140044872389712 [label="result1
 (1, 8)" fillcolor=orange]
	140044872494912 -> 140044872528176 [dir=none]
	140044872528176 [label="result2
 (1, 8)" fillcolor=orange]
	140044872494912 -> 140052779984992 [dir=none]
	140052779984992 [label="weight
 (512)" fillcolor=orange]
	140044872494912 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :             16
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872519984 -> 140044872494912
	140044872519984 -> 140044873120960 [dir=none]
	140044873120960 [label="input
 (1, 512, 16)" fillcolor=orange]
	140044872519984 -> 140052779984832 [dir=none]
	140052779984832 [label="weight
 (512, 512, 5)" fillcolor=orange]
	140044872519984 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (512,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872494048 -> 140044872519984
	140044872494048 [label="AddBackward0
------------
alpha: 1"]
	140044872520560 -> 140044872494048
	140044872520560 -> 140044873120800 [dir=none]
	140044873120800 [label="self
 (1, 512, 16)" fillcolor=orange]
	140044872520560 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872520704 -> 140044872520560
	140044872520704 -> 140044873120720 [dir=none]
	140044873120720 [label="input
 (1, 512, 16)" fillcolor=orange]
	140044872520704 -> 140044872528336 [dir=none]
	140044872528336 [label="result1
 (1, 8)" fillcolor=orange]
	140044872520704 -> 140044872528256 [dir=none]
	140044872528256 [label="result2
 (1, 8)" fillcolor=orange]
	140044872520704 -> 140052779984432 [dir=none]
	140052779984432 [label="weight
 (512)" fillcolor=orange]
	140044872520704 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :             16
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872520800 -> 140044872520704
	140044872520800 -> 140044873120640 [dir=none]
	140044873120640 [label="input
 (1, 512, 16)" fillcolor=orange]
	140044872520800 -> 140052779982912 [dir=none]
	140052779982912 [label="weight
 (512, 512, 5)" fillcolor=orange]
	140044872520800 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (512,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872520992 -> 140044872520800
	140044872520992 [label="AddBackward0
------------
alpha: 1"]
	140044872521184 -> 140044872520992
	140044872521184 -> 140044873120160 [dir=none]
	140044873120160 [label="other
 (1, 512, 16)" fillcolor=orange]
	140044872521184 -> 140044873120400 [dir=none]
	140044873120400 [label="self
 (1, 512, 1)" fillcolor=orange]
	140044872521184 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140044872521328 -> 140044872521184
	140044872521328 [label="SelectBackward0
--------------------------
dim       :              1
index     :              0
self_sizes: (1, 2, 512, 1)"]
	140044872521472 -> 140044872521328
	140044872521472 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:      (1, 2, 512, 1)
start     :                   0
step      :                   1"]
	140044872521568 -> 140044872521472
	140044872521568 [label="ReshapeAliasBackward0
------------------------
self_sizes: (1, 1024, 1)"]
	140044872521664 -> 140044872521568
	140044872521664 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 1024)"]
	140044872521760 -> 140044872521664
	140044872521760 [label="PermuteBackward0
----------------
dims: (0, 1)"]
	140044872521856 -> 140044872521760
	140044872521856 [label="ReshapeAliasBackward0
---------------------
self_sizes: (1, 1024)"]
	140044872521952 -> 140044872521856
	140044872521952 -> 140044873120240 [dir=none]
	140044873120240 [label="mat1
 (1, 402)" fillcolor=orange]
	140044872521952 -> 140044872528656 [dir=none]
	140044872528656 [label="mat2
 (402, 1024)" fillcolor=orange]
	140044872521952 [label="AddmmBackward0
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 402)
mat1_strides:       (402, 1)
mat2        : [saved tensor]
mat2_sizes  :    (402, 1024)
mat2_strides:       (1, 402)"]
	140044872522048 -> 140044872521952
	140052779983872 [label="model.down_modules.0.0.cond_encoder.1.bias
 (1024)" fillcolor=lightblue]
	140052779983872 -> 140044872522048
	140044872522048 [label=AccumulateGrad]
	140044872522000 -> 140044872521952
	140044872522000 -> 140044873119600 [dir=none]
	140044873119600 [label="self
 (1, 402)" fillcolor=orange]
	140044872522000 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872648688 -> 140044872522000
	140044872521376 -> 140044872521952
	140044872521376 [label=TBackward0]
	140044872522240 -> 140044872521376
	140052779983312 [label="model.down_modules.0.0.cond_encoder.1.weight
 (1024, 402)" fillcolor=lightblue]
	140052779983312 -> 140044872522240
	140044872522240 [label=AccumulateGrad]
	140044872521280 -> 140044872521184
	140044872521280 -> 140044873120080 [dir=none]
	140044873120080 [label="self
 (1, 512, 16)" fillcolor=orange]
	140044872521280 [label="MishBackward0
--------------------
self: [saved tensor]"]
	140044872521616 -> 140044872521280
	140044872521616 -> 140044873120000 [dir=none]
	140044873120000 [label="input
 (1, 512, 16)" fillcolor=orange]
	140044872521616 -> 140044872528576 [dir=none]
	140044872528576 [label="result1
 (1, 8)" fillcolor=orange]
	140044872521616 -> 140044872528736 [dir=none]
	140044872528736 [label="result2
 (1, 8)" fillcolor=orange]
	140044872521616 -> 140052779983392 [dir=none]
	140052779983392 [label="weight
 (512)" fillcolor=orange]
	140044872521616 [label="NativeGroupNormBackward0
------------------------
C      :            512
HxW    :             16
N      :              1
eps    :          1e-05
group  :              8
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	140044872521808 -> 140044872521616
	140044872521808 -> 140044873115744 [dir=none]
	140044873115744 [label="input
 (1, 128, 16)" fillcolor=orange]
	140044872521808 -> 140052779984512 [dir=none]
	140052779984512 [label="weight
 (512, 128, 5)" fillcolor=orange]
	140044872521808 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (512,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (2,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872522336 -> 140044872521808
	140052779984512 [label="model.down_modules.0.0.blocks.0.block.0.weight
 (512, 128, 5)" fillcolor=lightblue]
	140052779984512 -> 140044872522336
	140044872522336 [label=AccumulateGrad]
	140044872522192 -> 140044872521808
	140052779984592 [label="model.down_modules.0.0.blocks.0.block.0.bias
 (512)" fillcolor=lightblue]
	140052779984592 -> 140044872522192
	140044872522192 [label=AccumulateGrad]
	140044872521712 -> 140044872521616
	140052779983392 [label="model.down_modules.0.0.blocks.0.block.1.weight
 (512)" fillcolor=lightblue]
	140052779983392 -> 140044872521712
	140044872521712 [label=AccumulateGrad]
	140044872521424 -> 140044872521616
	140052779983232 [label="model.down_modules.0.0.blocks.0.block.1.bias
 (512)" fillcolor=lightblue]
	140052779983232 -> 140044872521424
	140044872521424 [label=AccumulateGrad]
	140044872521136 -> 140044872520992
	140044872521136 [label="SelectBackward0
--------------------------
dim       :              1
index     :              1
self_sizes: (1, 2, 512, 1)"]
	140044872521904 -> 140044872521136
	140044872521904 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:      (1, 2, 512, 1)
start     :                   0
step      :                   1"]
	140044872521568 -> 140044872521904
	140044872520944 -> 140044872520800
	140052779982912 [label="model.down_modules.0.0.blocks.1.block.0.weight
 (512, 512, 5)" fillcolor=lightblue]
	140052779982912 -> 140044872520944
	140044872520944 [label=AccumulateGrad]
	140044872520896 -> 140044872520800
	140052779983952 [label="model.down_modules.0.0.blocks.1.block.0.bias
 (512)" fillcolor=lightblue]
	140052779983952 -> 140044872520896
	140044872520896 [label=AccumulateGrad]
	140044872520752 -> 140044872520704
	140052779984432 [label="model.down_modules.0.0.blocks.1.block.1.weight
 (512)" fillcolor=lightblue]
	140052779984432 -> 140044872520752
	140044872520752 [label=AccumulateGrad]
	140044872520608 -> 140044872520704
	140052779984032 [label="model.down_modules.0.0.blocks.1.block.1.bias
 (512)" fillcolor=lightblue]
	140052779984032 -> 140044872520608
	140044872520608 [label=AccumulateGrad]
	140044872520320 -> 140044872494048
	140044872520320 -> 140044873115744 [dir=none]
	140044873115744 [label="input
 (1, 128, 16)" fillcolor=orange]
	140044872520320 -> 140052779983472 [dir=none]
	140052779983472 [label="weight
 (512, 128, 1)" fillcolor=orange]
	140044872520320 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (512,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (0,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872521040 -> 140044872520320
	140052779983472 [label="model.down_modules.0.0.residual_conv.weight
 (512, 128, 1)" fillcolor=lightblue]
	140052779983472 -> 140044872521040
	140044872521040 [label=AccumulateGrad]
	140044872520848 -> 140044872520320
	140052779984752 [label="model.down_modules.0.0.residual_conv.bias
 (512)" fillcolor=lightblue]
	140052779984752 -> 140044872520848
	140044872520848 [label=AccumulateGrad]
	140044872520512 -> 140044872519984
	140052779984832 [label="model.down_modules.0.1.blocks.0.block.0.weight
 (512, 512, 5)" fillcolor=lightblue]
	140052779984832 -> 140044872520512
	140044872520512 [label=AccumulateGrad]
	140044872520368 -> 140044872519984
	140052779984912 [label="model.down_modules.0.1.blocks.0.block.0.bias
 (512)" fillcolor=lightblue]
	140052779984912 -> 140044872520368
	140044872520368 [label=AccumulateGrad]
	140044872519888 -> 140044872494912
	140052779984992 [label="model.down_modules.0.1.blocks.0.block.1.weight
 (512)" fillcolor=lightblue]
	140052779984992 -> 140044872519888
	140044872519888 [label=AccumulateGrad]
	140044872519792 -> 140044872494912
	140052779985072 [label="model.down_modules.0.1.blocks.0.block.1.bias
 (512)" fillcolor=lightblue]
	140052779985072 -> 140044872519792
	140044872519792 [label=AccumulateGrad]
	140044872494672 -> 140044872494528
	140044872494672 [label="SelectBackward0
--------------------------
dim       :              1
index     :              1
self_sizes: (1, 2, 512, 1)"]
	140044872494960 -> 140044872494672
	140044872494960 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:      (1, 2, 512, 1)
start     :                   0
step      :                   1"]
	140044872495056 -> 140044872494960
	140044872494480 -> 140044872494336
	140052779985152 [label="model.down_modules.0.1.blocks.1.block.0.weight
 (512, 512, 5)" fillcolor=lightblue]
	140052779985152 -> 140044872494480
	140044872494480 [label=AccumulateGrad]
	140044872494432 -> 140044872494336
	140052779985232 [label="model.down_modules.0.1.blocks.1.block.0.bias
 (512)" fillcolor=lightblue]
	140052779985232 -> 140044872494432
	140044872494432 [label=AccumulateGrad]
	140044872494288 -> 140044872494240
	140052779985312 [label="model.down_modules.0.1.blocks.1.block.1.weight
 (512)" fillcolor=lightblue]
	140052779985312 -> 140044872494288
	140044872494288 [label=AccumulateGrad]
	140044872494144 -> 140044872494240
	140052779985392 [label="model.down_modules.0.1.blocks.1.block.1.bias
 (512)" fillcolor=lightblue]
	140052779985392 -> 140044872494144
	140044872494144 [label=AccumulateGrad]
	140044872494048 -> 140044872493904
	140044872493856 -> 140044872493808
	140052779985632 [label="model.down_modules.0.2.conv.weight
 (512, 512, 3)" fillcolor=lightblue]
	140052779985632 -> 140044872493856
	140044872493856 [label=AccumulateGrad]
	140044872493616 -> 140044872493808
	140052779985712 [label="model.down_modules.0.2.conv.bias
 (512)" fillcolor=lightblue]
	140052779985712 -> 140044872493616
	140044872493616 [label=AccumulateGrad]
	140044872493664 -> 140044872493280
	140052779985792 [label="model.down_modules.1.0.blocks.0.block.0.weight
 (1024, 512, 5)" fillcolor=lightblue]
	140052779985792 -> 140044872493664
	140044872493664 [label=AccumulateGrad]
	140044872493568 -> 140044872493280
	140052779985872 [label="model.down_modules.1.0.blocks.0.block.0.bias
 (1024)" fillcolor=lightblue]
	140052779985872 -> 140044872493568
	140044872493568 [label=AccumulateGrad]
	140044872493184 -> 140044872493088
	140052779985952 [label="model.down_modules.1.0.blocks.0.block.1.weight
 (1024)" fillcolor=lightblue]
	140052779985952 -> 140044872493184
	140044872493184 [label=AccumulateGrad]
	140044872492896 -> 140044872493088
	140052779986032 [label="model.down_modules.1.0.blocks.0.block.1.bias
 (1024)" fillcolor=lightblue]
	140052779986032 -> 140044872492896
	140044872492896 [label=AccumulateGrad]
	140044872492608 -> 140044872492464
	140044872492608 [label="SelectBackward0
---------------------------
dim       :               1
index     :               1
self_sizes: (1, 2, 1024, 1)"]
	140044872493376 -> 140044872492608
	140044872493376 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 1024, 1)
start     :                   0
step      :                   1"]
	140044872493040 -> 140044872493376
	140044872492416 -> 140044872492272
	140052779986112 [label="model.down_modules.1.0.blocks.1.block.0.weight
 (1024, 1024, 5)" fillcolor=lightblue]
	140052779986112 -> 140044872492416
	140044872492416 [label=AccumulateGrad]
	140044872492368 -> 140044872492272
	140052779986192 [label="model.down_modules.1.0.blocks.1.block.0.bias
 (1024)" fillcolor=lightblue]
	140052779986192 -> 140044872492368
	140044872492368 [label=AccumulateGrad]
	140044872492224 -> 140044872492176
	140052779986272 [label="model.down_modules.1.0.blocks.1.block.1.weight
 (1024)" fillcolor=lightblue]
	140052779986272 -> 140044872492224
	140044872492224 [label=AccumulateGrad]
	140044872492080 -> 140044872492176
	140052779986352 [label="model.down_modules.1.0.blocks.1.block.1.bias
 (1024)" fillcolor=lightblue]
	140052779986352 -> 140044872492080
	140044872492080 [label=AccumulateGrad]
	140044872491792 -> 140044872465520
	140044872491792 -> 140044873121280 [dir=none]
	140044873121280 [label="input
 (1, 512, 8)" fillcolor=orange]
	140044872491792 -> 140052779986592 [dir=none]
	140052779986592 [label="weight
 (1024, 512, 1)" fillcolor=orange]
	140044872491792 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (1024,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (0,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872493808 -> 140044872491792
	140044872492512 -> 140044872491792
	140052779986592 [label="model.down_modules.1.0.residual_conv.weight
 (1024, 512, 1)" fillcolor=lightblue]
	140052779986592 -> 140044872492512
	140044872492512 [label=AccumulateGrad]
	140044872492320 -> 140044872491792
	140052779986672 [label="model.down_modules.1.0.residual_conv.bias
 (1024)" fillcolor=lightblue]
	140052779986672 -> 140044872492320
	140044872492320 [label=AccumulateGrad]
	140044872491984 -> 140044872491456
	140052779986752 [label="model.down_modules.1.1.blocks.0.block.0.weight
 (1024, 1024, 5)" fillcolor=lightblue]
	140052779986752 -> 140044872491984
	140044872491984 [label=AccumulateGrad]
	140044872491840 -> 140044872491456
	140052779986832 [label="model.down_modules.1.1.blocks.0.block.0.bias
 (1024)" fillcolor=lightblue]
	140052779986832 -> 140044872491840
	140044872491840 [label=AccumulateGrad]
	140044872491360 -> 140044872491264
	140052779466816 [label="model.down_modules.1.1.blocks.0.block.1.weight
 (1024)" fillcolor=lightblue]
	140052779466816 -> 140044872491360
	140044872491360 [label=AccumulateGrad]
	140044872491072 -> 140044872491264
	140052779466896 [label="model.down_modules.1.1.blocks.0.block.1.bias
 (1024)" fillcolor=lightblue]
	140052779466896 -> 140044872491072
	140044872491072 [label=AccumulateGrad]
	140044872466144 -> 140044872466000
	140044872466144 [label="SelectBackward0
---------------------------
dim       :               1
index     :               1
self_sizes: (1, 2, 1024, 1)"]
	140044872466240 -> 140044872466144
	140044872466240 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 1024, 1)
start     :                   0
step      :                   1"]
	140044872491216 -> 140044872466240
	140044872465952 -> 140044872465808
	140052779466976 [label="model.down_modules.1.1.blocks.1.block.0.weight
 (1024, 1024, 5)" fillcolor=lightblue]
	140052779466976 -> 140044872465952
	140044872465952 [label=AccumulateGrad]
	140044872465904 -> 140044872465808
	140052779467056 [label="model.down_modules.1.1.blocks.1.block.0.bias
 (1024)" fillcolor=lightblue]
	140052779467056 -> 140044872465904
	140044872465904 [label=AccumulateGrad]
	140044872465760 -> 140044872465712
	140052779467136 [label="model.down_modules.1.1.blocks.1.block.1.weight
 (1024)" fillcolor=lightblue]
	140052779467136 -> 140044872465760
	140044872465760 [label=AccumulateGrad]
	140044872465616 -> 140044872465712
	140052779467216 [label="model.down_modules.1.1.blocks.1.block.1.bias
 (1024)" fillcolor=lightblue]
	140052779467216 -> 140044872465616
	140044872465616 [label=AccumulateGrad]
	140044872465520 -> 140044872841248
	140044872465424 -> 140044872465328
	140052779467456 [label="model.down_modules.1.2.conv.weight
 (1024, 1024, 3)" fillcolor=lightblue]
	140052779467456 -> 140044872465424
	140044872465424 [label=AccumulateGrad]
	140044872465376 -> 140044872465328
	140052779467536 [label="model.down_modules.1.2.conv.bias
 (1024)" fillcolor=lightblue]
	140052779467536 -> 140044872465376
	140044872465376 [label=AccumulateGrad]
	140044872465184 -> 140044872464800
	140052779467616 [label="model.down_modules.2.0.blocks.0.block.0.weight
 (2048, 1024, 5)" fillcolor=lightblue]
	140052779467616 -> 140044872465184
	140044872465184 [label=AccumulateGrad]
	140044872465088 -> 140044872464800
	140052779467696 [label="model.down_modules.2.0.blocks.0.block.0.bias
 (2048)" fillcolor=lightblue]
	140052779467696 -> 140044872465088
	140044872465088 [label=AccumulateGrad]
	140044872464704 -> 140044872464608
	140052779467776 [label="model.down_modules.2.0.blocks.0.block.1.weight
 (2048)" fillcolor=lightblue]
	140052779467776 -> 140044872464704
	140044872464704 [label=AccumulateGrad]
	140044872464416 -> 140044872464608
	140052779467856 [label="model.down_modules.2.0.blocks.0.block.1.bias
 (2048)" fillcolor=lightblue]
	140052779467856 -> 140044872464416
	140044872464416 [label=AccumulateGrad]
	140044872464128 -> 140044872463984
	140044872464128 [label="SelectBackward0
---------------------------
dim       :               1
index     :               1
self_sizes: (1, 2, 2048, 1)"]
	140044872464896 -> 140044872464128
	140044872464896 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 2048, 1)
start     :                   0
step      :                   1"]
	140044872464560 -> 140044872464896
	140044872463936 -> 140044872463792
	140052779467936 [label="model.down_modules.2.0.blocks.1.block.0.weight
 (2048, 2048, 5)" fillcolor=lightblue]
	140052779467936 -> 140044872463936
	140044872463936 [label=AccumulateGrad]
	140044872463888 -> 140044872463792
	140052779468016 [label="model.down_modules.2.0.blocks.1.block.0.bias
 (2048)" fillcolor=lightblue]
	140052779468016 -> 140044872463888
	140044872463888 [label=AccumulateGrad]
	140044872463744 -> 140044872463696
	140052779468096 [label="model.down_modules.2.0.blocks.1.block.1.weight
 (2048)" fillcolor=lightblue]
	140052779468096 -> 140044872463744
	140044872463744 [label=AccumulateGrad]
	140044872463600 -> 140044872463696
	140052779468176 [label="model.down_modules.2.0.blocks.1.block.1.bias
 (2048)" fillcolor=lightblue]
	140052779468176 -> 140044872463600
	140044872463600 [label=AccumulateGrad]
	140044872463312 -> 140044872424560
	140044872463312 -> 140044873127232 [dir=none]
	140044873127232 [label="input
 (1, 1024, 4)" fillcolor=orange]
	140044872463312 -> 140052779468416 [dir=none]
	140052779468416 [label="weight
 (2048, 1024, 1)" fillcolor=orange]
	140044872463312 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (2048,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (0,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872465328 -> 140044872463312
	140044872464032 -> 140044872463312
	140052779468416 [label="model.down_modules.2.0.residual_conv.weight
 (2048, 1024, 1)" fillcolor=lightblue]
	140052779468416 -> 140044872464032
	140044872464032 [label=AccumulateGrad]
	140044872463840 -> 140044872463312
	140052779468496 [label="model.down_modules.2.0.residual_conv.bias
 (2048)" fillcolor=lightblue]
	140052779468496 -> 140044872463840
	140044872463840 [label=AccumulateGrad]
	140044872463504 -> 140044872462976
	140052779468576 [label="model.down_modules.2.1.blocks.0.block.0.weight
 (2048, 2048, 5)" fillcolor=lightblue]
	140052779468576 -> 140044872463504
	140044872463504 [label=AccumulateGrad]
	140044872463360 -> 140044872462976
	140052779468656 [label="model.down_modules.2.1.blocks.0.block.0.bias
 (2048)" fillcolor=lightblue]
	140052779468656 -> 140044872463360
	140044872463360 [label=AccumulateGrad]
	140044872462880 -> 140044872462784
	140052779468736 [label="model.down_modules.2.1.blocks.0.block.1.weight
 (2048)" fillcolor=lightblue]
	140052779468736 -> 140044872462880
	140044872462880 [label=AccumulateGrad]
	140044872462592 -> 140044872462784
	140052779468816 [label="model.down_modules.2.1.blocks.0.block.1.bias
 (2048)" fillcolor=lightblue]
	140052779468816 -> 140044872462592
	140044872462592 [label=AccumulateGrad]
	140044872425376 -> 140044872425232
	140044872425376 [label="SelectBackward0
---------------------------
dim       :               1
index     :               1
self_sizes: (1, 2, 2048, 1)"]
	140044872463072 -> 140044872425376
	140044872463072 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 2048, 1)
start     :                   0
step      :                   1"]
	140044872462736 -> 140044872463072
	140044872425184 -> 140044872425040
	140052779468896 [label="model.down_modules.2.1.blocks.1.block.0.weight
 (2048, 2048, 5)" fillcolor=lightblue]
	140052779468896 -> 140044872425184
	140044872425184 [label=AccumulateGrad]
	140044872425136 -> 140044872425040
	140052779468976 [label="model.down_modules.2.1.blocks.1.block.0.bias
 (2048)" fillcolor=lightblue]
	140052779468976 -> 140044872425136
	140044872425136 [label=AccumulateGrad]
	140044872424992 -> 140044872424944
	140052779469056 [label="model.down_modules.2.1.blocks.1.block.1.weight
 (2048)" fillcolor=lightblue]
	140052779469056 -> 140044872424992
	140044872424992 [label=AccumulateGrad]
	140044872424848 -> 140044872424944
	140052779469136 [label="model.down_modules.2.1.blocks.1.block.1.bias
 (2048)" fillcolor=lightblue]
	140052779469136 -> 140044872424848
	140044872424848 [label=AccumulateGrad]
	140044872424560 -> 140044872875600
	140044872424752 -> 140044872424224
	140052880928016 [label="model.mid_modules.0.blocks.0.block.0.weight
 (2048, 2048, 5)" fillcolor=lightblue]
	140052880928016 -> 140044872424752
	140044872424752 [label=AccumulateGrad]
	140044872424608 -> 140044872424224
	140052880926336 [label="model.mid_modules.0.blocks.0.block.0.bias
 (2048)" fillcolor=lightblue]
	140052880926336 -> 140044872424608
	140044872424608 [label=AccumulateGrad]
	140044872424128 -> 140044872424032
	140052785088768 [label="model.mid_modules.0.blocks.0.block.1.weight
 (2048)" fillcolor=lightblue]
	140052785088768 -> 140044872424128
	140044872424128 [label=AccumulateGrad]
	140044872423840 -> 140044872424032
	140052785088288 [label="model.mid_modules.0.blocks.0.block.1.bias
 (2048)" fillcolor=lightblue]
	140052785088288 -> 140044872423840
	140044872423840 [label=AccumulateGrad]
	140044872423552 -> 140044872423408
	140044872423552 [label="SelectBackward0
---------------------------
dim       :               1
index     :               1
self_sizes: (1, 2, 2048, 1)"]
	140044872424320 -> 140044872423552
	140044872424320 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 2048, 1)
start     :                   0
step      :                   1"]
	140044872423984 -> 140044872424320
	140044872423360 -> 140044872423216
	140052785088608 [label="model.mid_modules.0.blocks.1.block.0.weight
 (2048, 2048, 5)" fillcolor=lightblue]
	140052785088608 -> 140044872423360
	140044872423360 [label=AccumulateGrad]
	140044872423312 -> 140044872423216
	140052785090128 [label="model.mid_modules.0.blocks.1.block.0.bias
 (2048)" fillcolor=lightblue]
	140052785090128 -> 140044872423312
	140044872423312 [label=AccumulateGrad]
	140044872423168 -> 140044872423120
	140052785090368 [label="model.mid_modules.0.blocks.1.block.1.weight
 (2048)" fillcolor=lightblue]
	140052785090368 -> 140044872423168
	140044872423168 [label=AccumulateGrad]
	140044872422928 -> 140044872423120
	140052785089168 [label="model.mid_modules.0.blocks.1.block.1.bias
 (2048)" fillcolor=lightblue]
	140052785089168 -> 140044872422928
	140044872422928 [label=AccumulateGrad]
	140044872875600 -> 140044872875744
	140044872422976 -> 140044872422448
	140052785087568 [label="model.mid_modules.1.blocks.0.block.0.weight
 (2048, 2048, 5)" fillcolor=lightblue]
	140052785087568 -> 140044872422976
	140044872422976 [label=AccumulateGrad]
	140044872422832 -> 140044872422448
	140052785090288 [label="model.mid_modules.1.blocks.0.block.0.bias
 (2048)" fillcolor=lightblue]
	140052785090288 -> 140044872422832
	140044872422832 [label=AccumulateGrad]
	140044872422352 -> 140044872422256
	140052785089568 [label="model.mid_modules.1.blocks.0.block.1.weight
 (2048)" fillcolor=lightblue]
	140052785089568 -> 140044872422352
	140044872422352 [label=AccumulateGrad]
	140044872422064 -> 140044872422256
	140052785089488 [label="model.mid_modules.1.blocks.0.block.1.bias
 (2048)" fillcolor=lightblue]
	140052785089488 -> 140044872422064
	140044872422064 [label=AccumulateGrad]
	140044872421776 -> 140044872421632
	140044872421776 [label="SelectBackward0
---------------------------
dim       :               1
index     :               1
self_sizes: (1, 2, 2048, 1)"]
	140044872422544 -> 140044872421776
	140044872422544 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 2048, 1)
start     :                   0
step      :                   1"]
	140044872422208 -> 140044872422544
	140044872421584 -> 140044872875984
	140052785089808 [label="model.mid_modules.1.blocks.1.block.0.weight
 (2048, 2048, 5)" fillcolor=lightblue]
	140052785089808 -> 140044872421584
	140044872421584 [label=AccumulateGrad]
	140044872421536 -> 140044872875984
	140052785088688 [label="model.mid_modules.1.blocks.1.block.0.bias
 (2048)" fillcolor=lightblue]
	140052785088688 -> 140044872421536
	140044872421536 [label=AccumulateGrad]
	140044872875840 -> 140044872875936
	140052785088848 [label="model.mid_modules.1.blocks.1.block.1.weight
 (2048)" fillcolor=lightblue]
	140052785088848 -> 140044872875840
	140044872875840 [label=AccumulateGrad]
	140044872421440 -> 140044872875936
	140052785089008 [label="model.mid_modules.1.blocks.1.block.1.bias
 (2048)" fillcolor=lightblue]
	140052785089008 -> 140044872421440
	140044872421440 [label=AccumulateGrad]
	140044872875744 -> 140044872875648
	140044872875600 -> 140044872875552
	140044872875408 -> 140044872875024
	140052779469376 [label="model.up_modules.0.0.blocks.0.block.0.weight
 (1024, 4096, 5)" fillcolor=lightblue]
	140052779469376 -> 140044872875408
	140044872875408 [label=AccumulateGrad]
	140044872875312 -> 140044872875024
	140052779469456 [label="model.up_modules.0.0.blocks.0.block.0.bias
 (1024)" fillcolor=lightblue]
	140052779469456 -> 140044872875312
	140044872875312 [label=AccumulateGrad]
	140044872874928 -> 140044872874832
	140052779469536 [label="model.up_modules.0.0.blocks.0.block.1.weight
 (1024)" fillcolor=lightblue]
	140052779469536 -> 140044872874928
	140044872874928 [label=AccumulateGrad]
	140044872874640 -> 140044872874832
	140052779469616 [label="model.up_modules.0.0.blocks.0.block.1.bias
 (1024)" fillcolor=lightblue]
	140052779469616 -> 140044872874640
	140044872874640 [label=AccumulateGrad]
	140044872874352 -> 140044872874208
	140044872874352 [label="SelectBackward0
---------------------------
dim       :               1
index     :               1
self_sizes: (1, 2, 1024, 1)"]
	140044872875120 -> 140044872874352
	140044872875120 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 1024, 1)
start     :                   0
step      :                   1"]
	140044872874784 -> 140044872875120
	140044872874160 -> 140044872874016
	140052779469696 [label="model.up_modules.0.0.blocks.1.block.0.weight
 (1024, 1024, 5)" fillcolor=lightblue]
	140052779469696 -> 140044872874160
	140044872874160 [label=AccumulateGrad]
	140044872874112 -> 140044872874016
	140052779469776 [label="model.up_modules.0.0.blocks.1.block.0.bias
 (1024)" fillcolor=lightblue]
	140052779469776 -> 140044872874112
	140044872874112 [label=AccumulateGrad]
	140044872873968 -> 140044872873920
	140052779469856 [label="model.up_modules.0.0.blocks.1.block.1.weight
 (1024)" fillcolor=lightblue]
	140052779469856 -> 140044872873968
	140044872873968 [label=AccumulateGrad]
	140044872873824 -> 140044872873920
	140052779469936 [label="model.up_modules.0.0.blocks.1.block.1.bias
 (1024)" fillcolor=lightblue]
	140052779469936 -> 140044872873824
	140044872873824 [label=AccumulateGrad]
	140044872873536 -> 140044872842352
	140044872873536 -> 140044873129872 [dir=none]
	140044873129872 [label="input
 (1, 4096, 4)" fillcolor=orange]
	140044872873536 -> 140052779470176 [dir=none]
	140052779470176 [label="weight
 (1024, 4096, 1)" fillcolor=orange]
	140044872873536 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:        (1024,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (0,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872875552 -> 140044872873536
	140044872874256 -> 140044872873536
	140052779470176 [label="model.up_modules.0.0.residual_conv.weight
 (1024, 4096, 1)" fillcolor=lightblue]
	140052779470176 -> 140044872874256
	140044872874256 [label=AccumulateGrad]
	140044872874064 -> 140044872873536
	140052779470256 [label="model.up_modules.0.0.residual_conv.bias
 (1024)" fillcolor=lightblue]
	140052779470256 -> 140044872874064
	140044872874064 [label=AccumulateGrad]
	140044872873728 -> 140044872873200
	140052779470336 [label="model.up_modules.0.1.blocks.0.block.0.weight
 (1024, 1024, 5)" fillcolor=lightblue]
	140052779470336 -> 140044872873728
	140044872873728 [label=AccumulateGrad]
	140044872873584 -> 140044872873200
	140052779470416 [label="model.up_modules.0.1.blocks.0.block.0.bias
 (1024)" fillcolor=lightblue]
	140052779470416 -> 140044872873584
	140044872873584 [label=AccumulateGrad]
	140044872873104 -> 140044872873008
	140052779470496 [label="model.up_modules.0.1.blocks.0.block.1.weight
 (1024)" fillcolor=lightblue]
	140052779470496 -> 140044872873104
	140044872873104 [label=AccumulateGrad]
	140044872872816 -> 140044872873008
	140052779470576 [label="model.up_modules.0.1.blocks.0.block.1.bias
 (1024)" fillcolor=lightblue]
	140052779470576 -> 140044872872816
	140044872872816 [label=AccumulateGrad]
	140044872872528 -> 140044872843024
	140044872872528 [label="SelectBackward0
---------------------------
dim       :               1
index     :               1
self_sizes: (1, 2, 1024, 1)"]
	140044872873296 -> 140044872872528
	140044872873296 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:     (1, 2, 1024, 1)
start     :                   0
step      :                   1"]
	140044872872960 -> 140044872873296
	140044872872432 -> 140044872842832
	140052779470656 [label="model.up_modules.0.1.blocks.1.block.0.weight
 (1024, 1024, 5)" fillcolor=lightblue]
	140052779470656 -> 140044872872432
	140044872872432 [label=AccumulateGrad]
	140044872872048 -> 140044872842832
	140052779470736 [label="model.up_modules.0.1.blocks.1.block.0.bias
 (1024)" fillcolor=lightblue]
	140052779470736 -> 140044872872048
	140044872872048 [label=AccumulateGrad]
	140044872842448 -> 140044872842304
	140052779229248 [label="model.up_modules.0.1.blocks.1.block.1.weight
 (1024)" fillcolor=lightblue]
	140052779229248 -> 140044872842448
	140044872842448 [label=AccumulateGrad]
	140044872842064 -> 140044872842304
	140052779229328 [label="model.up_modules.0.1.blocks.1.block.1.bias
 (1024)" fillcolor=lightblue]
	140052779229328 -> 140044872842064
	140044872842064 [label=AccumulateGrad]
	140044872842352 -> 140044872841872
	140044872841824 -> 140044872840336
	140052880927296 [label="model.up_modules.0.2.conv.weight
 (1024, 1024, 4)" fillcolor=lightblue]
	140052880927296 -> 140044872841824
	140044872841824 [label=AccumulateGrad]
	140044872840480 -> 140044872840336
	140052779229568 [label="model.up_modules.0.2.conv.bias
 (1024)" fillcolor=lightblue]
	140052779229568 -> 140044872840480
	140044872840480 [label=AccumulateGrad]
	140044872841248 -> 140044872840096
	140044872839280 -> 140044872744048
	140052779229648 [label="model.up_modules.1.0.blocks.0.block.0.weight
 (512, 2048, 5)" fillcolor=lightblue]
	140052779229648 -> 140044872839280
	140044872839280 [label=AccumulateGrad]
	140044872839904 -> 140044872744048
	140052779229728 [label="model.up_modules.1.0.blocks.0.block.0.bias
 (512)" fillcolor=lightblue]
	140052779229728 -> 140044872839904
	140044872839904 [label=AccumulateGrad]
	140044872742800 -> 140044872743664
	140052779229808 [label="model.up_modules.1.0.blocks.0.block.1.weight
 (512)" fillcolor=lightblue]
	140052779229808 -> 140044872742800
	140044872742800 [label=AccumulateGrad]
	140044872742992 -> 140044872743664
	140052779229888 [label="model.up_modules.1.0.blocks.0.block.1.bias
 (512)" fillcolor=lightblue]
	140052779229888 -> 140044872742992
	140044872742992 [label=AccumulateGrad]
	140044872705312 -> 140044872681936
	140044872705312 [label="SelectBackward0
--------------------------
dim       :              1
index     :              1
self_sizes: (1, 2, 512, 1)"]
	140044872744096 -> 140044872705312
	140044872744096 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:      (1, 2, 512, 1)
start     :                   0
step      :                   1"]
	140044872743616 -> 140044872744096
	140044872681696 -> 140044872679920
	140052779229968 [label="model.up_modules.1.0.blocks.1.block.0.weight
 (512, 512, 5)" fillcolor=lightblue]
	140052779229968 -> 140044872681696
	140044872681696 [label=AccumulateGrad]
	140044872683040 -> 140044872679920
	140052779230048 [label="model.up_modules.1.0.blocks.1.block.0.bias
 (512)" fillcolor=lightblue]
	140052779230048 -> 140044872683040
	140044872683040 [label=AccumulateGrad]
	140044872681072 -> 140044872650512
	140052779230128 [label="model.up_modules.1.0.blocks.1.block.1.weight
 (512)" fillcolor=lightblue]
	140052779230128 -> 140044872681072
	140044872681072 [label=AccumulateGrad]
	140044872680016 -> 140044872650512
	140052779230208 [label="model.up_modules.1.0.blocks.1.block.1.bias
 (512)" fillcolor=lightblue]
	140052779230208 -> 140044872680016
	140044872680016 [label=AccumulateGrad]
	140044872648736 -> 140044872647008
	140044872648736 -> 140044873132368 [dir=none]
	140044873132368 [label="input
 (1, 2048, 8)" fillcolor=orange]
	140044872648736 -> 140052779230448 [dir=none]
	140052779230448 [label="weight
 (512, 2048, 1)" fillcolor=orange]
	140044872648736 [label="ConvolutionBackward0
------------------------------
bias_sizes_opt:         (512,)
dilation      :           (1,)
groups        :              1
input         : [saved tensor]
output_padding:           (0,)
padding       :           (0,)
stride        :           (1,)
transposed    :          False
weight        : [saved tensor]"]
	140044872840096 -> 140044872648736
	140044872679536 -> 140044872648736
	140052779230448 [label="model.up_modules.1.0.residual_conv.weight
 (512, 2048, 1)" fillcolor=lightblue]
	140052779230448 -> 140044872679536
	140044872679536 [label=AccumulateGrad]
	140044872650176 -> 140044872648736
	140052779230528 [label="model.up_modules.1.0.residual_conv.bias
 (512)" fillcolor=lightblue]
	140052779230528 -> 140044872650176
	140044872650176 [label=AccumulateGrad]
	140044872649120 -> 140044872648352
	140052779230608 [label="model.up_modules.1.1.blocks.0.block.0.weight
 (512, 512, 5)" fillcolor=lightblue]
	140052779230608 -> 140044872649120
	140044872649120 [label=AccumulateGrad]
	140044872648784 -> 140044872648352
	140052779230688 [label="model.up_modules.1.1.blocks.0.block.0.bias
 (512)" fillcolor=lightblue]
	140052779230688 -> 140044872648784
	140044872648784 [label=AccumulateGrad]
	140044872648256 -> 140044872648160
	140052779230768 [label="model.up_modules.1.1.blocks.0.block.1.weight
 (512)" fillcolor=lightblue]
	140052779230768 -> 140044872648256
	140044872648256 [label=AccumulateGrad]
	140044872647920 -> 140044872648160
	140052779230848 [label="model.up_modules.1.1.blocks.0.block.1.bias
 (512)" fillcolor=lightblue]
	140052779230848 -> 140044872647920
	140044872647920 [label=AccumulateGrad]
	140044872647632 -> 140044872647488
	140044872647632 [label="SelectBackward0
--------------------------
dim       :              1
index     :              1
self_sizes: (1, 2, 512, 1)"]
	140044872648448 -> 140044872647632
	140044872648448 [label="SliceBackward0
-------------------------------
dim       :                   0
end       : 9223372036854775807
self_sizes:      (1, 2, 512, 1)
start     :                   0
step      :                   1"]
	140044872648112 -> 140044872648448
	140044872647440 -> 140044872647296
	140052779230928 [label="model.up_modules.1.1.blocks.1.block.0.weight
 (512, 512, 5)" fillcolor=lightblue]
	140052779230928 -> 140044872647440
	140044872647440 [label=AccumulateGrad]
	140044872647392 -> 140044872647296
	140052779231008 [label="model.up_modules.1.1.blocks.1.block.0.bias
 (512)" fillcolor=lightblue]
	140052779231008 -> 140044872647392
	140044872647392 [label=AccumulateGrad]
	140044872647248 -> 140044872647200
	140052779231088 [label="model.up_modules.1.1.blocks.1.block.1.weight
 (512)" fillcolor=lightblue]
	140052779231088 -> 140044872647248
	140044872647248 [label=AccumulateGrad]
	140044872647104 -> 140044872647200
	140052779231168 [label="model.up_modules.1.1.blocks.1.block.1.bias
 (512)" fillcolor=lightblue]
	140052779231168 -> 140044872647104
	140044872647104 [label=AccumulateGrad]
	140044872647008 -> 140044872646864
	140044872646816 -> 140044873379792
	140052779231408 [label="model.up_modules.1.2.conv.weight
 (512, 512, 4)" fillcolor=lightblue]
	140052779231408 -> 140044872646816
	140044872646816 [label=AccumulateGrad]
	140044872646768 -> 140044873379792
	140052779231488 [label="model.up_modules.1.2.conv.bias
 (512)" fillcolor=lightblue]
	140052779231488 -> 140044872646768
	140044872646768 [label=AccumulateGrad]
	140044873379744 -> 140044873378208
	140052779231568 [label="model.final_conv.0.block.0.weight
 (512, 512, 5)" fillcolor=lightblue]
	140052779231568 -> 140044873379744
	140044873379744 [label=AccumulateGrad]
	140044873378064 -> 140044873378208
	140052779231648 [label="model.final_conv.0.block.0.bias
 (512)" fillcolor=lightblue]
	140052779231648 -> 140044873378064
	140044873378064 [label=AccumulateGrad]
	140044873378112 -> 140044873376144
	140052779231728 [label="model.final_conv.0.block.1.weight
 (512)" fillcolor=lightblue]
	140052779231728 -> 140044873378112
	140044873378112 [label=AccumulateGrad]
	140044873377968 -> 140044873376144
	140052779231808 [label="model.final_conv.0.block.1.bias
 (512)" fillcolor=lightblue]
	140052779231808 -> 140044873377968
	140044873377968 [label=AccumulateGrad]
	140044873379120 -> 140044873379072
	140052779231888 [label="model.final_conv.1.weight
 (128, 512, 1)" fillcolor=lightblue]
	140052779231888 -> 140044873379120
	140044873379120 [label=AccumulateGrad]
	140044873377200 -> 140044873379072
	140052779231968 [label="model.final_conv.1.bias
 (128)" fillcolor=lightblue]
	140052779231968 -> 140044873377200
	140044873377200 [label=AccumulateGrad]
	140043443897200 -> 140044873135664
}
